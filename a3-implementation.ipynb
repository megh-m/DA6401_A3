{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import wandb\nwandb.login(key = \"eb9574fa5b11da36782604ea27df8bf1989ddefd\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:18.434779Z","iopub.execute_input":"2025-05-15T15:11:18.435103Z","iopub.status.idle":"2025-05-15T15:11:20.222564Z","shell.execute_reply.started":"2025-05-15T15:11:18.435083Z","shell.execute_reply":"2025-05-15T15:11:20.218475Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/2477885884.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"eb9574fa5b11da36782604ea27df8bf1989ddefd\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36mlogin\u001b[0;34m(anonymous, key, relogin, host, force, timeout, verify)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \"\"\"\n\u001b[1;32m     75\u001b[0m     \u001b[0m_handle_host_wandb_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     return _login(\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0manonymous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manonymous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36m_login\u001b[0;34m(anonymous, key, relogin, host, force, timeout, verify, _silent, _disable_warning)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m     wlogin = _WandbLogin(\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0manonymous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manonymous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, anonymous, force, host, key, relogin, timeout)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_anonymous\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manonymous\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"must\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wandb_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wandb_setup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_from_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogin_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wandb_setup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(settings)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \"\"\"\n\u001b[0;32m--> 383\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\u001b[0m in \u001b[0;36m_setup\u001b[0;34m(settings, start_service)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0m_singleton\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0m_singleton\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WandbSetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstart_service\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_singleton\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_noop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pid, settings, environ)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_EarlyLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtermsetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\u001b[0m in \u001b[0;36m_settings_setup\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# infer settings from the system environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_from_system_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m# load SageMaker settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_settings.py\u001b[0m in \u001b[0;36mupdate_from_system_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1478\u001b[0m         \u001b[0;31m# Attempt to get notebook information if not already set by the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jupyter\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m             \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjupyter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1481\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_jupyter_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_jupyter_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/jupyter.py\u001b[0m in \u001b[0;36mnotebook_metadata\u001b[0;34m(silent)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Colab:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# request the most recent contents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mipynb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattempt_colab_load_ipynb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mipynb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mjupyter_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             return {\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/jupyter.py\u001b[0m in \u001b[0;36mattempt_colab_load_ipynb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m# This isn't thread safe, never call in a thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get_ipynb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ipynb\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":50},{"cell_type":"code","source":"!pip install jiwer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.223285Z","iopub.status.idle":"2025-05-15T15:11:20.223586Z","shell.execute_reply.started":"2025-05-15T15:11:20.223450Z","shell.execute_reply":"2025-05-15T15:11:20.223465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_SILENT\"] = \"false\"\nos.environ[\"WANDB_START_METHOD\"] = \"thread\"\nos.environ[\"WANDB_API_KEY\"] = \"eb9574fa5b11da36782604ea27df8bf1989ddefd\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.225007Z","iopub.status.idle":"2025-05-15T15:11:20.225316Z","shell.execute_reply.started":"2025-05-15T15:11:20.225192Z","shell.execute_reply":"2025-05-15T15:11:20.225205Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport random\nimport torch.nn.functional as F","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.227227Z","iopub.status.idle":"2025-05-15T15:11:20.227628Z","shell.execute_reply.started":"2025-05-15T15:11:20.227423Z","shell.execute_reply":"2025-05-15T15:11:20.227441Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"class CharEmbed(nn.Module):\n    def __init__(self, input_dim, embed_dim):\n        super(CharEmbed, self).__init__()\n        self.embed = nn.Embedding(input_dim, embed_dim)\n    \n    def forward(self, input_seq):\n        return self.embed(input_seq)\n\nclass EncoderRNN(nn.Module):\n    def __init__(self, input_dim, embed_dim, hidden_dim, n_layers=1, \n                 cell_type='GRU', dropout=0.0, bidirectional=False):\n        super(EncoderRNN, self).__init__()\n        self.embed = nn.Embedding(input_dim, embed_dim)\n        self.hidden_dim = hidden_dim\n        self.n_layers = n_layers\n        self.cell_type = cell_type\n        self.bidirectional = bidirectional #to allow forward and backward time step data processing\n        # Cell type options GRU, LSTM & vanilla RNN\n        if cell_type == 'GRU':\n            self.rnn = nn.GRU(embed_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0, bidirectional=bidirectional)\n        elif cell_type == 'LSTM':\n            self.rnn = nn.LSTM(embed_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0, bidirectional=bidirectional)\n        else: \n            self.rnn = nn.RNN(embed_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0, bidirectional=bidirectional)\n    \n    def forward(self, input_seq, input_lengths, hidden=None):\n        # Sort sequences by length\n        input_lengths, sort_idx = torch.sort(input_lengths, descending=True)\n        input_seq = input_seq[:, sort_idx]  # (seq_len, batch_size, ...)\n        \n        # Convert to embeddings\n        embedded = self.embed(input_seq)\n        \n        # Pack with enforce_sorted=False\n        packed = nn.utils.rnn.pack_padded_sequence(\n            embedded, \n            input_lengths.cpu(), \n            enforce_sorted=False\n        )\n        \n        # Forward pass\n        outputs, hidden = self.rnn(packed, hidden)\n        \n        # Unpack padding\n        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n        \n        # Restore original order\n        _, unsort_idx = torch.sort(sort_idx)\n        outputs = outputs[:, unsort_idx]\n        \n        # Handle LSTM hidden/cell states\n        if isinstance(hidden, tuple):\n            hidden = (\n                hidden[0][:, unsort_idx],  # Hidden state\n                hidden[1][:, unsort_idx]   # Cell state\n            )\n        else:  # For GRU/RNN\n            hidden = hidden[:, unsort_idx]\n        \n        return outputs, hidden\n\nclass DecoderRNN(nn.Module): #Basically similar to the encoder, will have a softmax to predict next char\n    def __init__(self, output_dim, embed_dim, hidden_dim, vocab, n_layers=1, cell_type='GRU', dropout=0.0, go_idx=1, stop_idx=2):\n        super(DecoderRNN, self).__init__()\n        self.embed = nn.Embedding(output_dim, embed_dim)\n        self.hidden_dim = hidden_dim\n        self.output_dim = output_dim\n        self.n_layers = n_layers\n        self.cell_type = cell_type\n        self.go_idx = go_idx\n        self.stop_idx = stop_idx\n        self.vocab = vocab\n        if cell_type == 'GRU':\n            self.rnn = nn.GRU(embed_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0)\n        elif cell_type == 'LSTM':\n            self.rnn = nn.LSTM(embed_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0)\n        else:\n            self.rnn = nn.RNN(embed_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0)\n        \n        self.out = nn.Linear(hidden_dim, output_dim)\n        self.softmax = nn.LogSoftmax(dim=1)\n        \n    def forward(self, input, hidden):\n        # Get embedding of current input character\n        embedded = self.embed(input).unsqueeze(0)\n        \n        # Forward pass through decoder\n        output, hidden = self.rnn(embedded, hidden)\n        \n        # Predict next character probabilities\n        output = self.softmax(self.out(output.squeeze(0)))\n        \n        return output, hidden\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.228810Z","iopub.status.idle":"2025-05-15T15:11:20.229158Z","shell.execute_reply.started":"2025-05-15T15:11:20.229025Z","shell.execute_reply":"2025-05-15T15:11:20.229039Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Seq2Seq(nn.Module): #Flexible enough to use different encoders other than the ones we define\n    def __init__(self, input_dim, output_dim, embed_dim, hidden_dim, num_layers, cell_type, dropout, device,vocab, go_idx=1, stop_idx=2):\n        #super().__init__()\n        super(Seq2Seq, self).__init__()\n        self.device = device\n        self.go_idx = go_idx\n        self.stop_idx = stop_idx\n        self.vocab = vocab\n            # Internal encoder creation\n        self.encoder = EncoderRNN(\n            input_dim=input_dim,\n            embed_dim=embed_dim,\n            hidden_dim=hidden_dim,\n            n_layers=num_layers,\n            cell_type=cell_type,\n            dropout=dropout\n        )\n        \n        # Internal decoder creation\n        self.decoder = DecoderRNN(\n            output_dim=output_dim,\n            embed_dim=embed_dim,\n            hidden_dim=hidden_dim,\n            n_layers=num_layers,\n            cell_type=cell_type,\n            dropout=dropout,\n            vocab = vocab,\n            go_idx = go_idx,\n            stop_idx = stop_idx\n        )\n        self.device = device \n    def forward(self, src, src_len, trg, teacher_forcing_ratio=0.5):\n        batch_size = src.shape[1]\n        trg_len = trg.shape[0]\n        trg_vocab_size = self.decoder.output_dim\n        \n        # Tensor to store decoder outputs\n        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n        \n        # Last hidden state of the encoder\n        encoder_outputs, hidden = self.encoder(src, src_len)\n        \n        # First input to the decoder is the <go> token\n        input = trg[0,:]\n        \n        for t in range(1, trg_len):\n            output, hidden = self.decoder(input, hidden)\n            outputs[t] = output\n            \n            # To Decide if we're going to use teacher forcing or not as needed\n            teacher_force = random.random() < teacher_forcing_ratio\n            \n            # Get the highest predicted token from our predictions\n            top1 = output.argmax(1)\n            \n            # If we use teacher forcing, we have to use actual next token as next input\n            # If not, use predicted token\n            input = trg[t] if teacher_force else top1\n        \n        return outputs\n        \n    def beam_search(self, src, src_len, beam_width=5, max_len=50):\n        \"\"\"Batch-friendly beam search implementation\"\"\"\n        self.eval()\n        batch_size = src.size(1)\n        \n        # Initialize beams with GO token\n        beams = torch.full((batch_size * beam_width, max_len), \n                          self.decoder.stop_idx, \n                          device=self.device)\n        beams[:, 0] = self.decoder.go_idx\n        beam_scores = torch.zeros(batch_size * beam_width, device=self.device)\n        \n        # Encode source sequence\n        encoder_outputs, hidden = self.encoder(src, src_len)\n        \n        # Expand hidden states\n        if isinstance(hidden, tuple):  # LSTM\n            hidden = (\n                hidden[0].repeat(1, beam_width, 1),\n                hidden[1].repeat(1, beam_width, 1)\n            )\n        else:  # GRU/RNN\n            hidden = hidden.repeat(1, beam_width, 1)\n        \n        for step in range(max_len-1):\n            decoder_input = beams[:, step]\n            output, hidden = self.decoder.forward(decoder_input, hidden)\n            \n            log_probs = F.log_softmax(output, dim=1)\n            topk_log_probs, topk_indices = torch.topk(log_probs, beam_width, dim=1)\n            \n            # Reshape scores\n            if step == 0:\n                # First step: (batch, beam) -> (batch, beam*beam)\n                expanded_scores = topk_log_probs.view(batch_size, -1)\n            else:\n                # Subsequent steps: (batch, beam, beam) -> (batch, beam*beam)\n                expanded_scores = beam_scores.view(batch_size, beam_width, 1) + \\\n                                 topk_log_probs.view(batch_size, beam_width, beam_width)\n                expanded_scores = expanded_scores.view(batch_size, -1)\n            \n            # Select top candidates\n            top_scores, top_indices = torch.topk(expanded_scores, beam_width, dim=1)\n            \n            # Calculate beam/token origins\n            beam_indices = top_indices // beam_width\n            token_indices = top_indices % beam_width\n            \n            # Update beams with CORRECT indices\n            beams = beams.view(batch_size, beam_width, -1)\n            beams = torch.cat([\n                beams[torch.arange(batch_size)[:, None], beam_indices],\n                token_indices.unsqueeze(-1)  # Correct index usage\n            ], dim=-1)\n            beams = beams.view(batch_size * beam_width, -1)\n            \n            # Update scores and hidden states\n            beam_scores = top_scores.view(-1)\n            if isinstance(hidden, tuple):\n                hidden = (\n                    hidden[0][:, beam_indices.view(-1), :].contiguous(),\n                    hidden[1][:, beam_indices.view(-1), :].contiguous()\n                )\n            else:\n                hidden = hidden[:, beam_indices.view(-1), :].contiguous()\n            \n            # Early stopping check\n            current_tokens = beams[:, step+1]\n            if (current_tokens == self.decoder.stop_idx).all():\n                break\n    \n        return self._process_beams(beams.view(batch_size, beam_width, -1))\n\n    def _process_beams(self, beams_tensor):\n        \"\"\"\n        Converts beam search output tensor into cleaned token sequences.\n        \n        Args:\n            beams_tensor: Tensor of shape (batch_size, beam_width, max_len)\n            \n        Returns:\n            List[List[List[str]]]: For each batch item, a list of beam sequences.\n        \"\"\"\n        batch_size, beam_width, max_len = beams_tensor.size()\n        processed_beams = []\n        \n        for batch_idx in range(batch_size):\n            batch_sequences = []\n            for beam_idx in range(beam_width):\n                # Extract token indices for this beam\n                indices = beams_tensor[batch_idx, beam_idx].tolist()\n                \n                # Remove <go> (go_idx) at the start if present\n                if indices[0] == self.decoder.go_idx:\n                    indices = indices[1:]  # Remove first element\n                \n                # Truncate at first <stop> (stop_idx)\n                try:\n                    stop_pos = indices.index(self.decoder.stop_idx)\n                    indices = indices[:stop_pos]  # Exclude <stop>\n                except ValueError:\n                    pass  # No <stop> found, use all tokens\n                \n                # Remove padding (assuming pad_idx = 0)\n                cleaned_indices = [idx for idx in indices if idx not in [0, self.decoder.go_idx, self.decoder.stop_idx]]\n                \n                # Convert indices to tokens\n                tokens = [self.decoder.vocab.idx2char[idx] for idx in cleaned_indices]\n                batch_sequences.append(tokens)\n            \n            processed_beams.append(batch_sequences)\n        \n        return processed_beams\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.230984Z","iopub.status.idle":"2025-05-15T15:11:20.231374Z","shell.execute_reply.started":"2025-05-15T15:11:20.231181Z","shell.execute_reply":"2025-05-15T15:11:20.231199Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset Loading & Preprocessing","metadata":{}},{"cell_type":"code","source":"import os\nimport tarfile\nimport requests\nimport pandas as pd\nfrom io import BytesIO\nfrom collections import defaultdict\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nimport wandb\n\n# Dataset Configuration\nDATASET_URL = \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\"\nDATA_DIR = \"./dakshina_dataset\"\nHI_LEXICON_DIR = os.path.join(DATA_DIR,\"dakshina_dataset_v1.0\", \"hi\", \"lexicons\") #For Hindi (Chosen Language)\n\ndef download_and_extract_dataset(): #Scripted Dataset Download\n    if not os.path.exists(DATA_DIR):\n        print(\"Downloading dataset...\")\n        response = requests.get(DATASET_URL)\n        file = tarfile.open(fileobj=BytesIO(response.content))\n        file.extractall(DATA_DIR)\n        print(\"Dataset extracted successfully\")\n\nclass TransliterationVocabulary: #Build Character Vocab and add go,stop, padding and unknown tokens\n    def __init__(self):\n        self.char2idx = defaultdict(lambda: len(self.char2idx))\n        self.idx2char = {}\n        self.special_tokens = ['<pad>', '<go>', '<stop>', '<unk>']\n        \n        # Initialize special tokens\n        for token in self.special_tokens:\n            self.char2idx[token]\n        \n        self.idx2char = {v: k for k, v in self.char2idx.items()}\n    \n    def add_word(self, word):\n        #print(word) #for debugging\n        for char in word:\n            self.char2idx[char]\n        self.idx2char = {v: k for k, v in self.char2idx.items()}\n\nclass TransliterationDataset(Dataset): #Dataset loader for Hindi\n    def __init__(self, split='train'):\n        self.split = split\n        self.data = self._load_data()\n        self.src_vocab = TransliterationVocabulary()\n        self.trg_vocab = TransliterationVocabulary()\n        \n        # Build vocabularies\n        for src,trg in self.data:\n            self.src_vocab.add_word(src)\n            self.trg_vocab.add_word(trg)\n    \n    def _load_data(self):\n        \"\"\"Load data from TSV files and filter non-string entries\"\"\"\n        file_map = {\n            'train': 'hi.translit.sampled.train.tsv',\n            'dev': 'hi.translit.sampled.dev.tsv',\n            'test': 'hi.translit.sampled.test.tsv'\n        }\n        \n        df = pd.read_csv(\n            os.path.join(HI_LEXICON_DIR, file_map[self.split]),\n            sep='\\t', \n            header=None,\n            names=['devanagari', 'latin', 'count'],\n            dtype={'latin': str, 'devanagari': str, 'count':int}  # Force string type\n        )\n        \n        # Filter out non-string entries and empty strings\n        valid_entries = [\n            (latin, devanagari) \n            for latin, devanagari in zip(df['latin'], df['devanagari'])\n            if (isinstance(latin, str) and \n                isinstance(devanagari, str) and\n                len(latin) > 0 and \n                len(devanagari) > 0)\n        ]\n        \n        return valid_entries\n\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        src, trg = self.data[idx]\n        return (\n            [self.src_vocab.char2idx['<go>']] + \n            [self.src_vocab.char2idx[c] for c in src if c not in ['<go>','<stop>','<pad>','<unk>']] +\n            [self.src_vocab.char2idx['<stop>']],\n            [self.trg_vocab.char2idx['<go>']] + \n            [self.trg_vocab.char2idx[c] for c in trg if c not in ['<go>','<stop>','<pad>','<unk>']] +\n            [self.trg_vocab.char2idx['<stop>']]\n        )\n\ndef collate_fn(batch): #Padding and Masking\n    src_batch, trg_batch = zip(*batch)\n    \n    src_lens = torch.tensor([len(x) for x in src_batch])\n    trg_lens = torch.tensor([len(x) for x in trg_batch])\n    \n    src_pad = pad_sequence(\n        [torch.tensor(x) for x in src_batch],\n        padding_value=0  # <pad> token index\n    )\n    \n    trg_pad = pad_sequence(\n        [torch.tensor(x) for x in trg_batch],\n        padding_value=0  # <pad> token index\n    )\n    \n    return src_pad, trg_pad, src_lens, trg_lens\n\ndef get_dataloaders(batch_size=64):\n    \"\"\"Create train, dev, test dataloaders\"\"\"\n    download_and_extract_dataset()\n    \n    train_dataset = TransliterationDataset('train')\n    dev_dataset = TransliterationDataset('dev')\n    test_dataset = TransliterationDataset('test')\n    \n    return (\n        DataLoader(train_dataset, batch_size=batch_size, \n                  shuffle=True, collate_fn=collate_fn),\n        DataLoader(dev_dataset, batch_size=batch_size, \n                 collate_fn=collate_fn),\n        DataLoader(test_dataset, batch_size=batch_size,\n                 collate_fn=collate_fn),\n        train_dataset.src_vocab,\n        train_dataset.trg_vocab\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.232711Z","iopub.status.idle":"2025-05-15T15:11:20.233122Z","shell.execute_reply.started":"2025-05-15T15:11:20.232932Z","shell.execute_reply":"2025-05-15T15:11:20.232951Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\ndf = pd.read_csv(\n            os.path.join(HI_LEXICON_DIR,'hi.translit.sampled.train.tsv'),\n            sep='\\t',  #specifying seperator\n            header=None,\n            names=['devanagari','latin','syllables']\n        )\nlist(zip(df['latin'], df['devanagari']))'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.234174Z","iopub.status.idle":"2025-05-15T15:11:20.234545Z","shell.execute_reply.started":"2025-05-15T15:11:20.234362Z","shell.execute_reply":"2025-05-15T15:11:20.234379Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom jiwer import cer, wer\nfrom jiwer import visualize_alignment\n\nclass TransliterationMetrics:\n    @staticmethod\n    def preprocess_sequence(indices, vocab, remove_special=True):\n        \"\"\"Convert index tensor to cleaned character sequence\"\"\"\n        chars = []\n        for idx in indices:\n            char = vocab.idx2char[idx]\n            if remove_special and char in ['<go>', '<stop>', '<pad>','<unk>']:\n                continue\n            chars.append(char)\n        return ''.join(chars)\n\ndef evaluate_cer(model, loader, device, beam_width=5):\n    \"\"\"Calculate Character Error Rate\"\"\"\n    model.eval()\n    total_cer = 0.0\n    total = 0\n    \n    with torch.no_grad():\n        for src, trg, src_lens, trg_lens in loader:\n            src = src.to(device)\n            \n            # Get beam search predictions\n            beam_outputs = model.beam_search(src, src_lens, beam_width)\n            \n            # Process batch\n            for i in range(src.size(1)):\n                # Get target sequence\n                target_indices = trg[1:trg_lens[i]-1, i].cpu().tolist()\n                target_str = TransliterationMetrics.preprocess_sequence(target_indices, model.decoder.vocab)\n                \n                # Get top prediction\n                pred_indices = beam_outputs[i][0]\n                pred_str = TransliterationMetrics.preprocess_sequence(pred_indices, model.decoder.vocab)\n                \n                # Calculate CER\n                if target_str:  # Handle empty targets\n                    total_cer += cer(target_str, pred_str)\n                    total += 1\n                else:\n                    total_cer += 1.0  # Penalize completely wrong predictions\n                    total += 1\n                \n    return total_cer / total if total > 0 else 0\n\ndef evaluate_wer(model, loader, device, beam_width=5):\n    \"\"\"Calculate Word Error Rate (for reference)\"\"\"\n    model.eval()\n    total_wer = 0.0\n    total = 0\n    \n    with torch.no_grad():\n        for src, trg, src_lens, trg_lens in loader:\n            src = src.to(device)\n            \n            beam_outputs = model.beam_search(src, src_lens, beam_width)\n            \n            for i in range(src.size(1)):\n                target_indices = trg[1:trg_lens[i]-1, i].cpu().tolist()\n                target_str = TransliterationMetrics.preprocess_sequence(target_indices, model.decoder.vocab)\n                \n                pred_indices = beam_outputs[i][0]\n                pred_str = TransliterationMetrics.preprocess_sequence(pred_indices, model.decoder.vocab)\n                \n                if target_str:\n                    total_wer += wer(target_str, pred_str)\n                    total += 1\n                else:\n                    total_wer += 1.0\n                    total += 1\n                \n    return total_wer / total if total > 0 else 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.235878Z","iopub.status.idle":"2025-05-15T15:11:20.236168Z","shell.execute_reply.started":"2025-05-15T15:11:20.236035Z","shell.execute_reply":"2025-05-15T15:11:20.236046Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train Sweep","metadata":{}},{"cell_type":"code","source":"sweep_config = {\n    'method': 'bayes',\n    'metric': {'name': 'val_char_err', 'goal': 'minimize'},\n    'parameters': {\n        'embedding_size': {'values': [64, 128, 256]},\n        'hidden_size': {'values': [128, 256, 512]},\n        'num_layers': {'values': [1, 2, 3]},\n        'cell_type': {'values': ['LSTM', 'GRU', 'RNN']},\n        'dropout': {'values': [0.2, 0.3]},\n        'learning_rate': {'values': [0.001, 0.0005, 0.0001]},\n        'batch_size': {'values': [32, 64, 128]},\n        'bidirectional':{'values':[True, False]}\n    }\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.237069Z","iopub.status.idle":"2025-05-15T15:11:20.237323Z","shell.execute_reply.started":"2025-05-15T15:11:20.237205Z","shell.execute_reply":"2025-05-15T15:11:20.237216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train(config=None):\n    with wandb.init(project=\"DA6401_A3\",settings=wandb.Settings(start_method=\"thread\",_disable_stats=True), config = config) as run:\n        config = run.config\n        \n        # Get dataloaders and vocabularies\n        train_loader, dev_loader, _, src_vocab, trg_vocab = get_dataloaders(\n            batch_size=config.batch_size\n        )\n        go_idx = trg_vocab.char2idx['<go>']\n        stop_idx = trg_vocab.char2idx['stop']\n        # Initialize model\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        \n        model = Seq2Seq(\n            input_dim=len(src_vocab.char2idx),\n            output_dim=len(trg_vocab.char2idx),\n            embed_dim=config.embedding_size,\n            hidden_dim=config.hidden_size,\n            num_layers=config.num_layers,\n            cell_type=config.cell_type,\n            dropout=config.dropout,\n            device=device,\n            go_idx = go_idx,\n            stop_idx = stop_idx,\n            vocab = trg_vocab\n        ).to(device)\n        \n        # Training setup\n        optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n        criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n        \n        # Training loop\n        for epoch in range(15):  # Fixed epoch count for sweep\n            model.train()\n            total_loss = 0\n            \n            for src, trg, src_lens, trg_lens in train_loader:\n                src = src.to(device)\n                trg = trg.to(device)\n                \n                optimizer.zero_grad()\n                output = model(src, src_lens, trg)\n                \n                # Calculate loss\n                output_dim = output.shape[-1]\n                output = output[1:].view(-1, output_dim)\n                trg = trg[1:].view(-1)\n                \n                loss = criterion(output, trg)\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n                optimizer.step()\n                \n                total_loss += loss.item()\n            file_path = os.path.join(wandb.run.dir, \"model.pth\")\n            torch.save(model.state_dict(), file_path)\n            wandb.save('model.pth')\n            # Validation\n            #val_cer = evaluate_cer(model, dev_loader, device)\n            #val_wer = evaluate_wer(model, dev_loader, device)\n            val_acc = evaluate(model, dev_loader, device)\n            wandb.log({\n                'epoch': epoch,\n                'train_loss': total_loss/len(train_loader),\n                'val_acc': val_acc\n            })\n\ndef evaluate(model, loader, device):\n    model.eval()\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for src, trg, src_lens, trg_lens in loader:\n            src = src.to(device)\n            trg = trg.to(device)\n            \n            outputs = model(src, src_lens, trg, 0)  # No teacher forcing\n            outputs = outputs.argmax(dim=-1)\n            \n            # Calculate accuracy\n            mask = (trg != 0)\n            correct += ((outputs == trg) * mask).sum().item()\n            total += mask.sum().item()\n    \n    return correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.238258Z","iopub.status.idle":"2025-05-15T15:11:20.238483Z","shell.execute_reply.started":"2025-05-15T15:11:20.238375Z","shell.execute_reply":"2025-05-15T15:11:20.238385Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_with_beam(config=None):\n    with wandb.init(project=\"DA6401_A3\",settings=wandb.Settings(start_method=\"thread\",_disable_stats=True), config = config) as run:\n        config = run.config\n        \n        # Get dataloaders and vocabularies\n        train_loader, dev_loader, _, src_vocab, trg_vocab = get_dataloaders(\n            batch_size=config.batch_size\n        )\n        go_idx = trg_vocab.char2idx['<go>']\n        stop_idx = trg_vocab.char2idx['stop']\n        # Initialize model\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        \n        model = Seq2Seq(\n            input_dim=len(src_vocab.char2idx),\n            output_dim=len(trg_vocab.char2idx),\n            embed_dim=config.embedding_size,\n            hidden_dim=config.hidden_size,\n            num_layers=config.num_layers,\n            cell_type=config.cell_type,\n            dropout=config.dropout,\n            device=device,\n            go_idx = go_idx,\n            stop_idx = stop_idx,\n            vocab = trg_vocab\n        ).to(device)\n        \n        # Training setup\n        optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n        criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n        \n        # Training loop\n        for epoch in range(15):  # Fixed epoch count for sweep\n            model.train()\n            total_loss = 0\n            \n            for src, trg, src_lens, trg_lens in train_loader:\n                src = src.to(device)\n                trg = trg.to(device)\n                \n                optimizer.zero_grad()\n                output = model(src, src_lens, trg)\n                \n                # Calculate loss\n                output_dim = output.shape[-1]\n                output = output[1:].view(-1, output_dim)\n                trg = trg[1:].view(-1)\n                \n                loss = criterion(output, trg)\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n                optimizer.step()\n                \n                total_loss += loss.item()\n            file_path = os.path.join(wandb.run.dir, \"model.pth\")\n            torch.save(model.state_dict(), file_path)\n            wandb.save('model.pth')\n            # Validation\n            val_cer = evaluate_cer(model, dev_loader, device)\n            val_wer = evaluate_wer(model, dev_loader, device)\n            #val_acc = evaluate(model, dev_loader, device)\n            wandb.log({\n                'epoch': epoch,\n                'train_loss': total_loss/len(train_loader),\n                'val_char_err': val_cer,\n                'val_word_err': val_wer\n            })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.239375Z","iopub.status.idle":"2025-05-15T15:11:20.239631Z","shell.execute_reply.started":"2025-05-15T15:11:20.239519Z","shell.execute_reply":"2025-05-15T15:11:20.239530Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader, dev_loader, test_loader, src_vocab, trg_vocab = get_dataloaders()\nprint(f\"Source vocab size: {len(src_vocab.char2idx)}\")\nprint(f\"Target vocab size: {len(trg_vocab.char2idx)}\")\nprint(f\"Training batches: {len(train_loader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.240401Z","iopub.status.idle":"2025-05-15T15:11:20.240735Z","shell.execute_reply.started":"2025-05-15T15:11:20.240570Z","shell.execute_reply":"2025-05-15T15:11:20.240585Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#TransliterationDataset('test').data[2][1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.241817Z","iopub.status.idle":"2025-05-15T15:11:20.242081Z","shell.execute_reply.started":"2025-05-15T15:11:20.241966Z","shell.execute_reply":"2025-05-15T15:11:20.241977Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"src_vocab.char2idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.243718Z","iopub.status.idle":"2025-05-15T15:11:20.244093Z","shell.execute_reply.started":"2025-05-15T15:11:20.243918Z","shell.execute_reply":"2025-05-15T15:11:20.243933Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#src_vocab.idx2char","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.245649Z","iopub.status.idle":"2025-05-15T15:11:20.246034Z","shell.execute_reply.started":"2025-05-15T15:11:20.245845Z","shell.execute_reply":"2025-05-15T15:11:20.245861Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''# Initialize sweep\nsweep_id = wandb.sweep(\n    sweep=sweep_config,  # Your sweep configuration dictionary\n    project=\"DA6401_A3\",\n    entity=\"megh_m-iit-madras\"\n)\n\n# Run sweep agents\nwandb.agent(sweep_id, function=train, count = 10)'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.247213Z","iopub.status.idle":"2025-05-15T15:11:20.247931Z","shell.execute_reply.started":"2025-05-15T15:11:20.247615Z","shell.execute_reply":"2025-05-15T15:11:20.247636Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_alignment_example(model, sample):\n    src, trg = sample\n    pred = model.beam_search(src.unsqueeze(1), [len(src)], beam_width=1)[0][0]\n    \n    target_str = TransliterationMetrics.preprocess_sequence(trg[1:-1], model.decoder.vocab)\n    pred_str = TransliterationMetrics.preprocess_sequence(pred, model.decoder.vocab)\n    \n    print(\"CER:\", cer(target_str, pred_str))\n    print(\"Target:\", target_str)\n    print(\"Predicted:\", pred_str)\n    visualize_alignment(target_str, pred_str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.249346Z","iopub.status.idle":"2025-05-15T15:11:20.249638Z","shell.execute_reply.started":"2025-05-15T15:11:20.249516Z","shell.execute_reply":"2025-05-15T15:11:20.249526Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# For analysis\n'''sample = next(iter(dev_loader))\nshow_alignment_example(model, sample[0][0], sample[1][0])'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.251462Z","iopub.status.idle":"2025-05-15T15:11:20.251857Z","shell.execute_reply.started":"2025-05-15T15:11:20.251646Z","shell.execute_reply":"2025-05-15T15:11:20.251664Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nbest_model = Seq2Seq(\n            input_dim=len(src_vocab.char2idx),\n            output_dim=len(trg_vocab.char2idx)+1,\n            embed_dim=128,\n            hidden_dim=256,\n            num_layers=1,\n            cell_type='LSTM',\n            dropout=0.2,\n            device=device,\n            go_idx = trg_vocab.char2idx['<go>'],\n            stop_idx = trg_vocab.char2idx['<stop>'],\n            vocab = trg_vocab\n        ).to(device)\nbest_model.load_state_dict(torch.load('/kaggle/input/model_no_beam/pytorch/default/1/model_no-beam.pth', map_location = torch.device('cpu'), weights_only = True))\nbest_model.eval()\nevaluate(best_model, test_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.253614Z","iopub.status.idle":"2025-05-15T15:11:20.253974Z","shell.execute_reply.started":"2025-05-15T15:11:20.253829Z","shell.execute_reply":"2025-05-15T15:11:20.253845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with torch.no_grad():\n        for src, trg, src_lens, trg_lens in test_loader:\n            src = src.to(device)\n            trg = trg.to(device)\n            \n            outputs = best_model(src, src_lens, trg, 0)  # No teacher forcing\n            #outputs = outputs.argmax(dim=-1)\n\noutputs.size()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.256110Z","iopub.status.idle":"2025-05-15T15:11:20.256485Z","shell.execute_reply.started":"2025-05-15T15:11:20.256276Z","shell.execute_reply":"2025-05-15T15:11:20.256292Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = []\nwith torch.no_grad():\n    for src, trg, src_lens, trg_lens in test_loader:\n        src = src.to(device)\n        \n        # Forward pass through encoder\n        encoder_outputs, hidden = best_model.encoder(src, src_lens)\n        \n        # Greedy decoding\n        batch_size = src.size(1)\n        decoder_input = torch.full((1, batch_size), best_model.decoder.go_idx, device=device, dtype=torch.long)\n        \n        predictions = torch.zeros(50, batch_size, device=device, dtype=torch.long)\n\n        for t in range(50):\n            decoder_output, hidden = best_model.decoder(decoder_input.squeeze(0), hidden)\n            topi = decoder_output.argmax(1)\n            predictions[t] = topi\n            decoder_input = topi.unsqueeze(0)\n\n        # Process batch\n        for i in range(batch_size):\n            # Get source sequence\n            src_indices = src[:,i].cpu().numpy()\n            src_str = ''.join([src_vocab.idx2char[idx] for idx in src_indices if idx not in [0,1,2,3]])\n            \n            # Get prediction\n            pred_indices = predictions[:,i].cpu().numpy()\n            pred_str = ''.join([trg_vocab.idx2char[idx] for idx in pred_indices if idx not in [0,1,2,3]])\n            \n            results.append({\n                'Source': src_str,\n                'Prediction': pred_str,\n                'Target': ''.join([trg_vocab.idx2char[idx] for idx in trg[:,i].cpu().numpy() if idx not in [0,1,2,3]])\n            })\n\npd.DataFrame(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.258051Z","iopub.status.idle":"2025-05-15T15:11:20.258423Z","shell.execute_reply.started":"2025-05-15T15:11:20.258240Z","shell.execute_reply":"2025-05-15T15:11:20.258255Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"src_vocab.char2idx['a']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.259637Z","iopub.status.idle":"2025-05-15T15:11:20.260032Z","shell.execute_reply.started":"2025-05-15T15:11:20.259838Z","shell.execute_reply":"2025-05-15T15:11:20.259855Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nwith torch.no_grad():\n    for src, trg, src_lens, trg_lens in test_loader:\n        src = src.to(device)\n        trg = trg.to(device)\n        for i in range(1):\n            # Get source sequence\n            src_indices = src[:,i].cpu().numpy()\n            src_str = ''.join([src_vocab.idx2char[idx] for idx in src_indices if idx not in [0, 1, 2, 3]])\n            print(src_str) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.261695Z","iopub.status.idle":"2025-05-15T15:11:20.262095Z","shell.execute_reply.started":"2025-05-15T15:11:20.261899Z","shell.execute_reply":"2025-05-15T15:11:20.261925Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"src_str","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.263195Z","iopub.status.idle":"2025-05-15T15:11:20.263559Z","shell.execute_reply.started":"2025-05-15T15:11:20.263378Z","shell.execute_reply":"2025-05-15T15:11:20.263395Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"src, trg = TransliterationDataset('test').data[2]\nfor c in src:\n    print(c)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.265198Z","iopub.status.idle":"2025-05-15T15:11:20.265565Z","shell.execute_reply.started":"2025-05-15T15:11:20.265383Z","shell.execute_reply":"2025-05-15T15:11:20.265399Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"[src_vocab.char2idx['<go>']] + [src_vocab.char2idx[c] for c in src if c not in ['<go>','<stop>','<pad>','<unk>']] +[src_vocab.char2idx['<stop>']]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.267017Z","iopub.status.idle":"2025-05-15T15:11:20.267380Z","shell.execute_reply.started":"2025-05-15T15:11:20.267197Z","shell.execute_reply":"2025-05-15T15:11:20.267213Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# With Attention","metadata":{}},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, enc_hidden_dim, dec_hidden_dim):\n        super().__init__()\n        # Project encoder outputs to decoder's hidden space\n        self.enc_proj = nn.Linear(enc_hidden_dim, dec_hidden_dim)\n        # Project decoder hidden state\n        self.dec_proj = nn.Linear(dec_hidden_dim, dec_hidden_dim)\n        # Energy layer\n        self.energy = nn.Linear(dec_hidden_dim, 1)\n        \n    def forward(self, decoder_hidden, encoder_outputs):\n        # decoder_hidden: (1, batch_size, dec_hidden_dim)\n        # encoder_outputs: (seq_len, batch_size, enc_hidden_dim)\n        \n        # Project both to same dimension\n        dec_proj = self.dec_proj(decoder_hidden.squeeze(0))  # (batch_size, dec_hidden)\n        enc_proj = self.enc_proj(encoder_outputs)  # (seq_len, batch_size, dec_hidden)\n        \n        # Expand and combine\n        dec_proj = dec_proj.unsqueeze(1)  # (batch_size, 1, dec_hidden)\n        enc_proj = enc_proj.permute(1, 0, 2)  # (batch_size, seq_len, dec_hidden)\n        \n        # Calculate scores\n        scores = self.energy(torch.tanh(dec_proj + enc_proj))  # (batch_size, seq_len, 1)\n        attn_weights = F.softmax(scores, dim=1)\n        context = torch.bmm(attn_weights.permute(0,2,1), enc_proj) \n        return context, attn_weights\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.269290Z","iopub.status.idle":"2025-05-15T15:11:20.269659Z","shell.execute_reply.started":"2025-05-15T15:11:20.269477Z","shell.execute_reply":"2025-05-15T15:11:20.269493Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Attention2(nn.Module):\n    def __init__(self, hidden_size):\n        super(Attention2, self).__init__()\n        self.encoder_proj = nn.Linear(hidden_size, hidden_size)\n        self.decoder_proj = nn.Linear(hidden_size, hidden_size)\n        self.energy = nn.Linear(hidden_size, 1)\n        \n    def forward(self, decoder_hidden, encoder_outputs):\n        # decoder_hidden: (num_layers, batch_size, hidden_size)\n        # encoder_outputs: (seq_len, batch_size, hidden_size)\n        \n        # Project decoder hidden state\n        decoder_projected = self.decoder_proj(decoder_hidden[-1].unsqueeze(1))  # (batch_size, 1, hidden_size)\n        \n        # Project encoder outputs\n        encoder_projected = self.encoder_proj(encoder_outputs.permute(1,0,2))  # (batch_size, seq_len, hidden_size)\n        \n        # Calculate attention scores\n        scores = self.energy(torch.tanh(decoder_projected + encoder_projected))  # (batch_size, seq_len, 1)\n        attn_weights = F.softmax(scores, dim=1)  # (batch_size, seq_len, 1)\n        \n        # Calculate context vector\n        context = torch.bmm(attn_weights.permute(0,2,1), encoder_projected)  # (batch_size, 1, hidden_size)\n        \n        return context.squeeze(1), attn_weights.squeeze(2)  # (batch_size, hidden_size), (batch_size, seq_len)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:12:02.303019Z","iopub.execute_input":"2025-05-15T15:12:02.303319Z","iopub.status.idle":"2025-05-15T15:12:02.311288Z","shell.execute_reply.started":"2025-05-15T15:12:02.303298Z","shell.execute_reply":"2025-05-15T15:12:02.310147Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"class AttnDecoderRNN(nn.Module):\n    def __init__(self, output_dim, embed_dim, hidden_dim, vocab, n_layers=1, cell_type='GRU', dropout=0.0, go_idx = 1, stop_idx = 2):\n        super(AttnDecoderRNN, self).__init__()\n        self.embed = nn.Embedding(output_dim, embed_dim)\n        self.attention = Attention2(hidden_dim)\n        self.cell_type = cell_type\n        self.hidden_dim = hidden_dim\n        self.n_layers = n_layers\n        self.go_idx = go_idx\n        self.stop_idx = stop_idx\n        self.vocab = vocab\n        \n        # RNN Cell Selection\n        if cell_type == 'GRU':\n            self.rnn = nn.GRU(embed_dim + hidden_dim, hidden_dim, \n                             n_layers, dropout=dropout if n_layers > 1 else 0)\n        elif cell_type == 'LSTM':\n            self.rnn = nn.LSTM(embed_dim + hidden_dim, hidden_dim,\n                              n_layers, dropout=dropout if n_layers > 1 else 0)\n        else:\n            self.rnn = nn.RNN(embed_dim + hidden_dim, hidden_dim,\n                             n_layers, dropout=dropout if n_layers > 1 else 0)\n            \n        self.out = nn.Linear(hidden_dim * 2, output_dim)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, input, hidden, encoder_outputs):\n        # input: (batch_size)\n        # hidden: (num_layers, batch_size, hidden_dim)\n        # encoder_outputs: (seq_len, batch_size, hidden_dim)\n        \n        embedded = self.dropout(self.embed(input)).unsqueeze(0)  # (1, batch_size, emb_dim)\n        \n        # Calculate attention context\n        context, attn_weights = self.attention(hidden, encoder_outputs)\n        context = context.unsqueeze(0)  # (1, batch_size, hidden_dim)\n        \n        # Combine embedded input and context\n        rnn_input = torch.cat((embedded, context), dim=2)  # (1, batch_size, emb_dim + hidden_dim)\n        \n        # RNN forward pass\n        output, hidden = self.rnn(rnn_input, hidden)\n        \n        # Final prediction\n        output = self.out(torch.cat((output.squeeze(0), context.squeeze(0)), dim=1))\n        output = F.log_softmax(output, dim=1)\n        \n        return output, hidden, attn_weights\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.273297Z","iopub.status.idle":"2025-05-15T15:11:20.273652Z","shell.execute_reply.started":"2025-05-15T15:11:20.273476Z","shell.execute_reply":"2025-05-15T15:11:20.273491Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AttnSeq2Seq(nn.Module):\n    def __init__(self, input_dim, output_dim, embed_dim, hidden_dim, num_layers, cell_type, dropout, device,vocab, go_idx=1, stop_idx=2):\n        super(AttnSeq2Seq, self).__init__()\n        self.go_idx = go_idx\n        self.stop_idx = stop_idx\n        self.vocab = vocab\n        self.encoder = EncoderRNN(\n            input_dim=input_dim,\n            embed_dim=embed_dim,\n            hidden_dim=hidden_dim,\n            n_layers=num_layers,\n            cell_type=cell_type,\n            dropout=dropout\n        )\n        \n        # Internal decoder creation\n        self.decoder = AttnDecoderRNN(\n            output_dim=output_dim,\n            embed_dim=embed_dim,\n            hidden_dim=hidden_dim,\n            n_layers=num_layers,\n            cell_type=cell_type,\n            dropout=dropout,\n            vocab = vocab,\n            go_idx = go_idx,\n            stop_idx = stop_idx\n        )\n        self.device = device \n        \n    def forward(self, src, src_len, trg, teacher_forcing_ratio=0.5):\n        batch_size = src.shape[1]\n        trg_len = trg.shape[0]\n        trg_vocab_size = self.decoder.out.out_features\n        \n        # Encoder forward pass\n        encoder_outputs, hidden = self.encoder(src, src_len)\n        \n        # Decoder initial input\n        dec_input = trg[0,:]  # <sos> token\n        \n        # Output tensor initialization\n        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n        attentions = torch.zeros(trg_len, batch_size, src.shape[0]).to(self.device)\n        \n        for t in range(1, trg_len):\n            dec_output, hidden, attn_weights = self.decoder(\n                dec_input, hidden, encoder_outputs\n            )\n            \n            outputs[t] = dec_output\n            attentions[t] = attn_weights\n            \n            # Teacher forcing decision\n            teacher_force = random.random() < teacher_forcing_ratio\n            top1 = dec_output.argmax(1)\n            dec_input = trg[t] if teacher_force else top1\n            \n        return outputs, attentions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.274809Z","iopub.status.idle":"2025-05-15T15:11:20.275271Z","shell.execute_reply.started":"2025-05-15T15:11:20.275130Z","shell.execute_reply":"2025-05-15T15:11:20.275150Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_with_attn(config=None):\n    with wandb.init(project=\"DA6401_A3\",settings=wandb.Settings(start_method=\"thread\",_disable_stats=True), config = config) as run:\n        config = run.config\n        \n        # Get dataloaders and vocabularies\n        train_loader, dev_loader, _, src_vocab, trg_vocab = get_dataloaders(\n            batch_size=config.batch_size\n        )\n        go_idx = trg_vocab.char2idx['<go>']\n        stop_idx = trg_vocab.char2idx['stop']\n        # Initialize model\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        \n        model = AttnSeq2Seq(\n            input_dim=len(src_vocab.char2idx),\n            output_dim=len(trg_vocab.char2idx),\n            embed_dim=config.embedding_size,\n            hidden_dim=config.hidden_size,\n            num_layers=config.num_layers,\n            cell_type=config.cell_type,\n            dropout=config.dropout,\n            device=device,\n            go_idx = go_idx,\n            stop_idx = stop_idx,\n            vocab = trg_vocab\n        ).to(device)\n        \n        # Training setup\n        optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n        criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n        \n        # Training loop\n        for epoch in range(15):  # Fixed epoch count for sweep\n            model.train()\n            total_loss = 0\n            \n            for src, trg, src_lens, trg_lens in train_loader:\n                src = src.to(device)\n                trg = trg.to(device)\n                \n                optimizer.zero_grad()\n                output, attn_wts = model(src, src_lens, trg)\n                \n                # Calculate loss\n                output_dim = output.shape[-1]\n                output = output[1:].view(-1, output_dim)\n                trg = trg[1:].view(-1)\n                \n                loss = criterion(output, trg)\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n                optimizer.step()\n                \n                total_loss += loss.item()\n            file_path = os.path.join(wandb.run.dir, \"attn_model.pth\")\n            torch.save(model.state_dict(), file_path)\n            wandb.save('attn_model.pth')\n            # Validation\n            #val_cer = evaluate_cer(model, dev_loader, device)\n            #val_wer = evaluate_wer(model, dev_loader, device)\n            val_acc = evaluate(model, dev_loader, device)\n            wandb.log({\n                'epoch': epoch,\n                'train_loss': total_loss/len(train_loader),\n                'val_acc': val_acc\n            })\n\ndef evaluate(model, loader, device):\n    model.eval()\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for src, trg, src_lens, trg_lens in loader:\n            src = src.to(device)\n            trg = trg.to(device)\n            \n            outputs, attn_wts = model(src, src_lens, trg, 0)  # No teacher forcing\n            outputs = outputs.argmax(dim=-1)\n            \n            # Calculate accuracy\n            mask = (trg != 0)\n            correct += ((outputs == trg) * mask).sum().item()\n            total += mask.sum().item()\n    \n    return correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:11:20.276391Z","iopub.status.idle":"2025-05-15T15:11:20.276741Z","shell.execute_reply.started":"2025-05-15T15:11:20.276534Z","shell.execute_reply":"2025-05-15T15:11:20.276560Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize sweep\nsweep_id = wandb.sweep(\n    sweep=sweep_config,  # Your sweep configuration dictionary\n    project=\"DA6401_A3\",\n    entity=\"megh_m-iit-madras\"\n)\n\n# Run sweep agents\nwandb.agent(sweep_id, function=train_with_attn, count = 10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T15:12:11.098880Z","iopub.execute_input":"2025-05-15T15:12:11.099231Z","execution_failed":"2025-05-15T15:12:27.292Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: x4o8v2m7\nSweep URL: https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/x4o8v2m7\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6jgmyu2z with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DA6401_A3' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250515_151219-6jgmyu2z</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/6jgmyu2z' target=\"_blank\">genial-sweep-1</a></strong> to <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/x4o8v2m7' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/x4o8v2m7</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/x4o8v2m7' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/x4o8v2m7</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/6jgmyu2z' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/6jgmyu2z</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_35/3572231744.py\", line 42, in train_with_attn\n    output, attn_wts = model(src, src_lens, trg)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/988819618.py\", line 46, in forward\n    dec_output, hidden, attn_weights = self.decoder(\n                                       ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/1173793551.py\", line 35, in forward\n    context, attn_weights = self.attention(hidden, encoder_outputs)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/145032833.py\", line 19, in forward\n    scores = self.energy(torch.tanh(decoder_projected + encoder_projected))  # (batch_size, seq_len, 1)\n                                    ~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~\nRuntimeError: The size of tensor a (64) must match the size of tensor b (16) at non-singleton dimension 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}],"execution_count":null}]}