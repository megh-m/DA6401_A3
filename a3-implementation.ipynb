{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":382782,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":316056,"modelId":336522}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import wandb\nwandb.login(key = \"eb9574fa5b11da36782604ea27df8bf1989ddefd\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T12:53:41.990801Z","iopub.execute_input":"2025-05-08T12:53:41.991456Z","iopub.status.idle":"2025-05-08T12:53:50.343157Z","shell.execute_reply.started":"2025-05-08T12:53:41.991430Z","shell.execute_reply":"2025-05-08T12:53:50.342638Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmegh_m\u001b[0m (\u001b[33mmegh_m-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"!pip install jiwer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T12:46:53.768553Z","iopub.execute_input":"2025-05-08T12:46:53.768955Z","iopub.status.idle":"2025-05-08T12:47:01.272094Z","shell.execute_reply.started":"2025-05-08T12:46:53.768934Z","shell.execute_reply":"2025-05-08T12:47:01.271353Z"}},"outputs":[{"name":"stdout","text":"Collecting jiwer\n  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\nCollecting rapidfuzz>=3.9.7 (from jiwer)\n  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nDownloading jiwer-3.1.0-py3-none-any.whl (22 kB)\nDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\nSuccessfully installed jiwer-3.1.0 rapidfuzz-3.13.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_SILENT\"] = \"false\"\nos.environ[\"WANDB_START_METHOD\"] = \"thread\"\nos.environ[\"WANDB_API_KEY\"] = \"eb9574fa5b11da36782604ea27df8bf1989ddefd\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T12:53:54.978673Z","iopub.execute_input":"2025-05-08T12:53:54.979293Z","iopub.status.idle":"2025-05-08T12:53:54.982709Z","shell.execute_reply.started":"2025-05-08T12:53:54.979273Z","shell.execute_reply":"2025-05-08T12:53:54.981976Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport random\nimport torch.nn.functional as F","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T08:09:03.478762Z","iopub.execute_input":"2025-05-09T08:09:03.479093Z","iopub.status.idle":"2025-05-09T08:09:08.721352Z","shell.execute_reply.started":"2025-05-09T08:09:03.479069Z","shell.execute_reply":"2025-05-09T08:09:08.720462Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"class CharEmbed(nn.Module):\n    def __init__(self, input_dim, embed_dim):\n        super(CharEmbed, self).__init__()\n        self.embed = nn.Embedding(input_dim, embed_dim)\n    \n    def forward(self, input_seq):\n        return self.embed(input_seq)\n\nclass EncoderRNN(nn.Module):\n    def __init__(self, input_dim, embed_dim, hidden_dim, n_layers=1, \n                 cell_type='GRU', dropout=0.0, bidirectional=False):\n        super(EncoderRNN, self).__init__()\n        self.embed = nn.Embedding(input_dim, embed_dim)\n        self.hidden_dim = hidden_dim\n        self.n_layers = n_layers\n        self.cell_type = cell_type\n        self.bidirectional = bidirectional #to allow forward and backward time step data processing\n        # Cell type options GRU, LSTM & vanilla RNN\n        if cell_type == 'GRU':\n            self.rnn = nn.GRU(embed_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0, bidirectional=bidirectional)\n        elif cell_type == 'LSTM':\n            self.rnn = nn.LSTM(embed_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0, bidirectional=bidirectional)\n        else: \n            self.rnn = nn.RNN(embed_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0, bidirectional=bidirectional)\n    \n    def forward(self, input_seq, input_lengths, hidden=None):\n        # Sort sequences by length\n        input_lengths, sort_idx = torch.sort(input_lengths, descending=True)\n        input_seq = input_seq[:, sort_idx]  # (seq_len, batch_size, ...)\n        \n        # Convert to embeddings\n        embedded = self.embed(input_seq)\n        \n        # Pack with enforce_sorted=False\n        packed = nn.utils.rnn.pack_padded_sequence(\n            embedded, \n            input_lengths.cpu(), \n            enforce_sorted=False\n        )\n        \n        # Forward pass\n        outputs, hidden = self.rnn(packed, hidden)\n        \n        # Unpack padding\n        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n        \n        # Restore original order\n        _, unsort_idx = torch.sort(sort_idx)\n        outputs = outputs[:, unsort_idx]\n        \n        # Handle LSTM hidden/cell states\n        if isinstance(hidden, tuple):\n            hidden = (\n                hidden[0][:, unsort_idx],  # Hidden state\n                hidden[1][:, unsort_idx]   # Cell state\n            )\n        else:  # For GRU/RNN\n            hidden = hidden[:, unsort_idx]\n        \n        return outputs, hidden\n\nclass DecoderRNN(nn.Module): #Basically similar to the encoder, will have a softmax to predict next char\n    def __init__(self, output_dim, embed_dim, hidden_dim, vocab, n_layers=1, cell_type='GRU', dropout=0.0, go_idx=1, stop_idx=2):\n        super(DecoderRNN, self).__init__()\n        self.embed = nn.Embedding(output_dim, embed_dim)\n        self.hidden_dim = hidden_dim\n        self.output_dim = output_dim\n        self.n_layers = n_layers\n        self.cell_type = cell_type\n        self.go_idx = go_idx\n        self.stop_idx = stop_idx\n        self.vocab = vocab\n        if cell_type == 'GRU':\n            self.rnn = nn.GRU(embed_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0)\n        elif cell_type == 'LSTM':\n            self.rnn = nn.LSTM(embed_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0)\n        else:\n            self.rnn = nn.RNN(embed_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0)\n        \n        self.out = nn.Linear(hidden_dim, output_dim)\n        self.softmax = nn.LogSoftmax(dim=1)\n        \n    def forward(self, input, hidden):\n        # Get embedding of current input character\n        embedded = self.embed(input).unsqueeze(0)\n        \n        # Forward pass through decoder\n        output, hidden = self.rnn(embedded, hidden)\n        \n        # Predict next character probabilities\n        output = self.softmax(self.out(output.squeeze(0)))\n        \n        return output, hidden\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T08:09:12.761881Z","iopub.execute_input":"2025-05-09T08:09:12.762429Z","iopub.status.idle":"2025-05-09T08:09:12.787007Z","shell.execute_reply.started":"2025-05-09T08:09:12.762396Z","shell.execute_reply":"2025-05-09T08:09:12.785630Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class Seq2Seq(nn.Module): #Flexible enough to use different encoders other than the ones we define\n    def __init__(self, input_dim, output_dim, embed_dim, hidden_dim, num_layers, cell_type, dropout, device,vocab, go_idx=1, stop_idx=2):\n        #super().__init__()\n        super(Seq2Seq, self).__init__()\n        self.device = device\n        self.go_idx = go_idx\n        self.stop_idx = stop_idx\n        self.vocab = vocab\n            # Internal encoder creation\n        self.encoder = EncoderRNN(\n            input_dim=input_dim,\n            embed_dim=embed_dim,\n            hidden_dim=hidden_dim,\n            n_layers=num_layers,\n            cell_type=cell_type,\n            dropout=dropout\n        )\n        \n        # Internal decoder creation\n        self.decoder = DecoderRNN(\n            output_dim=output_dim,\n            embed_dim=embed_dim,\n            hidden_dim=hidden_dim,\n            n_layers=num_layers,\n            cell_type=cell_type,\n            dropout=dropout,\n            vocab = vocab,\n            go_idx = go_idx,\n            stop_idx = stop_idx\n        )\n        self.device = device \n    def forward(self, src, src_len, trg, teacher_forcing_ratio=0.5):\n        batch_size = src.shape[1]\n        trg_len = trg.shape[0]\n        trg_vocab_size = self.decoder.output_dim\n        \n        # Tensor to store decoder outputs\n        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n        \n        # Last hidden state of the encoder\n        encoder_outputs, hidden = self.encoder(src, src_len)\n        \n        # First input to the decoder is the <go> token\n        input = trg[0,:]\n        \n        for t in range(1, trg_len):\n            output, hidden = self.decoder(input, hidden)\n            outputs[t] = output\n            \n            # To Decide if we're going to use teacher forcing or not as needed\n            teacher_force = random.random() < teacher_forcing_ratio\n            \n            # Get the highest predicted token from our predictions\n            top1 = output.argmax(1)\n            \n            # If we use teacher forcing, we have to use actual next token as next input\n            # If not, use predicted token\n            input = trg[t] if teacher_force else top1\n        \n        return outputs\n        \n    def beam_search(self, src, src_len, beam_width=5, max_len=50):\n        \"\"\"Batch-friendly beam search implementation\"\"\"\n        self.eval()\n        batch_size = src.size(1)\n        \n        # Initialize beams with GO token\n        beams = torch.full((batch_size * beam_width, max_len), \n                          self.decoder.stop_idx, \n                          device=self.device)\n        beams[:, 0] = self.decoder.go_idx\n        beam_scores = torch.zeros(batch_size * beam_width, device=self.device)\n        \n        # Encode source sequence\n        encoder_outputs, hidden = self.encoder(src, src_len)\n        \n        # Expand hidden states\n        if isinstance(hidden, tuple):  # LSTM\n            hidden = (\n                hidden[0].repeat(1, beam_width, 1),\n                hidden[1].repeat(1, beam_width, 1)\n            )\n        else:  # GRU/RNN\n            hidden = hidden.repeat(1, beam_width, 1)\n        \n        for step in range(max_len-1):\n            decoder_input = beams[:, step]\n            output, hidden = self.decoder.forward(decoder_input, hidden)\n            \n            log_probs = F.log_softmax(output, dim=1)\n            topk_log_probs, topk_indices = torch.topk(log_probs, beam_width, dim=1)\n            \n            # Reshape scores\n            if step == 0:\n                # First step: (batch, beam) -> (batch, beam*beam)\n                expanded_scores = topk_log_probs.view(batch_size, -1)\n            else:\n                # Subsequent steps: (batch, beam, beam) -> (batch, beam*beam)\n                expanded_scores = beam_scores.view(batch_size, beam_width, 1) + \\\n                                 topk_log_probs.view(batch_size, beam_width, beam_width)\n                expanded_scores = expanded_scores.view(batch_size, -1)\n            \n            # Select top candidates\n            top_scores, top_indices = torch.topk(expanded_scores, beam_width, dim=1)\n            \n            # Calculate beam/token origins\n            beam_indices = top_indices // beam_width\n            token_indices = top_indices % beam_width\n            \n            # Update beams with CORRECT indices\n            beams = beams.view(batch_size, beam_width, -1)\n            beams = torch.cat([\n                beams[torch.arange(batch_size)[:, None], beam_indices],\n                token_indices.unsqueeze(-1)  # Correct index usage\n            ], dim=-1)\n            beams = beams.view(batch_size * beam_width, -1)\n            \n            # Update scores and hidden states\n            beam_scores = top_scores.view(-1)\n            if isinstance(hidden, tuple):\n                hidden = (\n                    hidden[0][:, beam_indices.view(-1), :].contiguous(),\n                    hidden[1][:, beam_indices.view(-1), :].contiguous()\n                )\n            else:\n                hidden = hidden[:, beam_indices.view(-1), :].contiguous()\n            \n            # Early stopping check\n            current_tokens = beams[:, step+1]\n            if (current_tokens == self.decoder.stop_idx).all():\n                break\n    \n        return self._process_beams(beams.view(batch_size, beam_width, -1))\n\n    def _process_beams(self, beams_tensor):\n        \"\"\"\n        Converts beam search output tensor into cleaned token sequences.\n        \n        Args:\n            beams_tensor: Tensor of shape (batch_size, beam_width, max_len)\n            \n        Returns:\n            List[List[List[str]]]: For each batch item, a list of beam sequences.\n        \"\"\"\n        batch_size, beam_width, max_len = beams_tensor.size()\n        processed_beams = []\n        \n        for batch_idx in range(batch_size):\n            batch_sequences = []\n            for beam_idx in range(beam_width):\n                # Extract token indices for this beam\n                indices = beams_tensor[batch_idx, beam_idx].tolist()\n                \n                # Remove <go> (go_idx) at the start if present\n                if indices[0] == self.decoder.go_idx:\n                    indices = indices[1:]  # Remove first element\n                \n                # Truncate at first <stop> (stop_idx)\n                try:\n                    stop_pos = indices.index(self.decoder.stop_idx)\n                    indices = indices[:stop_pos]  # Exclude <stop>\n                except ValueError:\n                    pass  # No <stop> found, use all tokens\n                \n                # Remove padding (assuming pad_idx = 0)\n                cleaned_indices = [idx for idx in indices if idx not in [0, self.decoder.go_idx, self.decoder.stop_idx]]\n                \n                # Convert indices to tokens\n                tokens = [self.decoder.vocab.idx2char[idx] for idx in cleaned_indices]\n                batch_sequences.append(tokens)\n            \n            processed_beams.append(batch_sequences)\n        \n        return processed_beams\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T08:09:26.921366Z","iopub.execute_input":"2025-05-09T08:09:26.921732Z","iopub.status.idle":"2025-05-09T08:09:26.942867Z","shell.execute_reply.started":"2025-05-09T08:09:26.921657Z","shell.execute_reply":"2025-05-09T08:09:26.941719Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Dataset Loading & Preprocessing","metadata":{}},{"cell_type":"code","source":"import os\nimport tarfile\nimport requests\nimport pandas as pd\nfrom io import BytesIO\nfrom collections import defaultdict\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nimport wandb\n\n# Dataset Configuration\nDATASET_URL = \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\"\nDATA_DIR = \"./dakshina_dataset\"\nHI_LEXICON_DIR = os.path.join(DATA_DIR,\"dakshina_dataset_v1.0\", \"hi\", \"lexicons\") #For Hindi (Chosen Language)\n\ndef download_and_extract_dataset(): #Scripted Dataset Download\n    if not os.path.exists(DATA_DIR):\n        print(\"Downloading dataset...\")\n        response = requests.get(DATASET_URL)\n        file = tarfile.open(fileobj=BytesIO(response.content))\n        file.extractall(DATA_DIR)\n        print(\"Dataset extracted successfully\")\n\nclass TransliterationVocabulary: #Build Character Vocab and add go,stop, padding and unknown tokens\n    def __init__(self):\n        self.char2idx = defaultdict(lambda: len(self.char2idx))\n        self.idx2char = {}\n        self.special_tokens = ['<pad>', '<go>', '<stop>', '<unk>']\n        \n        # Initialize special tokens\n        for token in self.special_tokens:\n            self.char2idx[token]\n        \n        self.idx2char = {v: k for k, v in self.char2idx.items()}\n    \n    def add_word(self, word):\n        #print(word) #for debugging\n        for char in word:\n            self.char2idx[char]\n        self.idx2char = {v: k for k, v in self.char2idx.items()}\n\nclass TransliterationDataset(Dataset): #Dataset loader for Hindi\n    def __init__(self, split='train'):\n        self.split = split\n        self.data = self._load_data()\n        self.src_vocab = TransliterationVocabulary()\n        self.trg_vocab = TransliterationVocabulary()\n        \n        # Build vocabularies\n        for src,trg in self.data:\n            self.src_vocab.add_word(src)\n            self.trg_vocab.add_word(trg)\n    \n    def _load_data(self):\n        \"\"\"Load data from TSV files and filter non-string entries\"\"\"\n        file_map = {\n            'train': 'hi.translit.sampled.train.tsv',\n            'dev': 'hi.translit.sampled.dev.tsv',\n            'test': 'hi.translit.sampled.test.tsv'\n        }\n        \n        df = pd.read_csv(\n            os.path.join(HI_LEXICON_DIR, file_map[self.split]),\n            sep='\\t', \n            header=None,\n            names=['devanagari', 'latin', 'count'],\n            dtype={'latin': str, 'devanagari': str, 'count':int}  # Force string type\n        )\n        \n        # Filter out non-string entries and empty strings\n        valid_entries = [\n            (latin, devanagari) \n            for latin, devanagari in zip(df['latin'], df['devanagari'])\n            if (isinstance(latin, str) and \n                isinstance(devanagari, str) and\n                len(latin) > 0 and \n                len(devanagari) > 0)\n        ]\n        \n        return valid_entries\n\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        src, trg = self.data[idx]\n        return (\n            [self.src_vocab.char2idx['<go>']] + \n            [self.src_vocab.char2idx[c] for c in src if c not in ['<go>','<stop>','<pad>','<unk>']] +\n            [self.src_vocab.char2idx['<stop>']],\n            [self.trg_vocab.char2idx['<go>']] + \n            [self.trg_vocab.char2idx[c] for c in trg if c not in ['<go>','<stop>','<pad>','<unk>']] +\n            [self.trg_vocab.char2idx['<stop>']]\n        )\n\ndef collate_fn(batch): #Padding and Masking\n    src_batch, trg_batch = zip(*batch)\n    \n    src_lens = torch.tensor([len(x) for x in src_batch])\n    trg_lens = torch.tensor([len(x) for x in trg_batch])\n    \n    src_pad = pad_sequence(\n        [torch.tensor(x) for x in src_batch],\n        padding_value=0  # <pad> token index\n    )\n    \n    trg_pad = pad_sequence(\n        [torch.tensor(x) for x in trg_batch],\n        padding_value=0  # <pad> token index\n    )\n    \n    return src_pad, trg_pad, src_lens, trg_lens\n\ndef get_dataloaders(batch_size=64):\n    \"\"\"Create train, dev, test dataloaders\"\"\"\n    download_and_extract_dataset()\n    \n    train_dataset = TransliterationDataset('train')\n    dev_dataset = TransliterationDataset('dev')\n    test_dataset = TransliterationDataset('test')\n    \n    return (\n        DataLoader(train_dataset, batch_size=batch_size, \n                  shuffle=True, collate_fn=collate_fn),\n        DataLoader(dev_dataset, batch_size=batch_size, \n                 collate_fn=collate_fn),\n        DataLoader(test_dataset, batch_size=batch_size,\n                 collate_fn=collate_fn),\n        train_dataset.src_vocab,\n        train_dataset.trg_vocab\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T08:09:36.310629Z","iopub.execute_input":"2025-05-09T08:09:36.311085Z","iopub.status.idle":"2025-05-09T08:09:40.413183Z","shell.execute_reply.started":"2025-05-09T08:09:36.311057Z","shell.execute_reply":"2025-05-09T08:09:40.411957Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\ndf = pd.read_csv(\n            os.path.join(HI_LEXICON_DIR,'hi.translit.sampled.train.tsv'),\n            sep='\\t',  #specifying seperator\n            header=None,\n            names=['devanagari','latin','syllables']\n        )\nlist(zip(df['latin'], df['devanagari']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:53:28.399570Z","iopub.execute_input":"2025-05-03T17:53:28.399889Z","iopub.status.idle":"2025-05-03T17:53:28.471277Z","shell.execute_reply.started":"2025-05-03T17:53:28.399865Z","shell.execute_reply":"2025-05-03T17:53:28.470488Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"44204"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"import torch\nfrom jiwer import cer, wer\nfrom jiwer import visualize_alignment\n\nclass TransliterationMetrics:\n    @staticmethod\n    def preprocess_sequence(indices, vocab, remove_special=True):\n        \"\"\"Convert index tensor to cleaned character sequence\"\"\"\n        chars = []\n        for idx in indices:\n            char = vocab.idx2char[idx]\n            if remove_special and char in ['<go>', '<stop>', '<pad>','<unk>']:\n                continue\n            chars.append(char)\n        return ''.join(chars)\n\ndef evaluate_cer(model, loader, device, beam_width=5):\n    \"\"\"Calculate Character Error Rate\"\"\"\n    model.eval()\n    total_cer = 0.0\n    total = 0\n    \n    with torch.no_grad():\n        for src, trg, src_lens, trg_lens in loader:\n            src = src.to(device)\n            \n            # Get beam search predictions\n            beam_outputs = model.beam_search(src, src_lens, beam_width)\n            \n            # Process batch\n            for i in range(src.size(1)):\n                # Get target sequence\n                target_indices = trg[1:trg_lens[i]-1, i].cpu().tolist()\n                target_str = TransliterationMetrics.preprocess_sequence(target_indices, model.decoder.vocab)\n                \n                # Get top prediction\n                pred_indices = beam_outputs[i][0]\n                pred_str = TransliterationMetrics.preprocess_sequence(pred_indices, model.decoder.vocab)\n                \n                # Calculate CER\n                if target_str:  # Handle empty targets\n                    total_cer += cer(target_str, pred_str)\n                    total += 1\n                else:\n                    total_cer += 1.0  # Penalize completely wrong predictions\n                    total += 1\n                \n    return total_cer / total if total > 0 else 0\n\ndef evaluate_wer(model, loader, device, beam_width=5):\n    \"\"\"Calculate Word Error Rate (for reference)\"\"\"\n    model.eval()\n    total_wer = 0.0\n    total = 0\n    \n    with torch.no_grad():\n        for src, trg, src_lens, trg_lens in loader:\n            src = src.to(device)\n            \n            beam_outputs = model.beam_search(src, src_lens, beam_width)\n            \n            for i in range(src.size(1)):\n                target_indices = trg[1:trg_lens[i]-1, i].cpu().tolist()\n                target_str = TransliterationMetrics.preprocess_sequence(target_indices, model.decoder.vocab)\n                \n                pred_indices = beam_outputs[i][0]\n                pred_str = TransliterationMetrics.preprocess_sequence(pred_indices, model.decoder.vocab)\n                \n                if target_str:\n                    total_wer += wer(target_str, pred_str)\n                    total += 1\n                else:\n                    total_wer += 1.0\n                    total += 1\n                \n    return total_wer / total if total > 0 else 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T12:54:31.150076Z","iopub.execute_input":"2025-05-08T12:54:31.150975Z","iopub.status.idle":"2025-05-08T12:54:31.188201Z","shell.execute_reply.started":"2025-05-08T12:54:31.150949Z","shell.execute_reply":"2025-05-08T12:54:31.187377Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/3601693041.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjiwer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjiwer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualize_alignment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTransliterationMetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jiwer'"],"ename":"ModuleNotFoundError","evalue":"No module named 'jiwer'","output_type":"error"}],"execution_count":7},{"cell_type":"markdown","source":"# Train Sweep","metadata":{}},{"cell_type":"code","source":"sweep_config = {\n    'method': 'bayes',\n    'metric': {'name': 'val_char_err', 'goal': 'minimize'},\n    'parameters': {\n        'embedding_size': {'values': [64, 128, 256]},\n        'hidden_size': {'values': [128, 256, 512]},\n        'num_layers': {'values': [1, 2, 3]},\n        'cell_type': {'values': ['LSTM', 'GRU', 'RNN']},\n        'dropout': {'values': [0.2, 0.3]},\n        'learning_rate': {'values': [0.001, 0.0005, 0.0001]},\n        'batch_size': {'values': [32, 64, 128]},\n        'bidirectional':{'values':[True, False]}\n    }\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T12:54:41.866029Z","iopub.execute_input":"2025-05-08T12:54:41.866611Z","iopub.status.idle":"2025-05-08T12:54:41.871220Z","shell.execute_reply.started":"2025-05-08T12:54:41.866586Z","shell.execute_reply":"2025-05-08T12:54:41.870558Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def train(config=None):\n    with wandb.init(project=\"DA6401_A3\",settings=wandb.Settings(start_method=\"thread\",_disable_stats=True), config = config) as run:\n        config = run.config\n        \n        # Get dataloaders and vocabularies\n        train_loader, dev_loader, _, src_vocab, trg_vocab = get_dataloaders(\n            batch_size=config.batch_size\n        )\n        go_idx = trg_vocab.char2idx['<go>']\n        stop_idx = trg_vocab.char2idx['stop']\n        # Initialize model\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        \n        model = Seq2Seq(\n            input_dim=len(src_vocab.char2idx),\n            output_dim=len(trg_vocab.char2idx),\n            embed_dim=config.embedding_size,\n            hidden_dim=config.hidden_size,\n            num_layers=config.num_layers,\n            cell_type=config.cell_type,\n            dropout=config.dropout,\n            device=device,\n            go_idx = go_idx,\n            stop_idx = stop_idx,\n            vocab = trg_vocab\n        ).to(device)\n        \n        # Training setup\n        optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n        criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n        \n        # Training loop\n        for epoch in range(15):  # Fixed epoch count for sweep\n            model.train()\n            total_loss = 0\n            \n            for src, trg, src_lens, trg_lens in train_loader:\n                src = src.to(device)\n                trg = trg.to(device)\n                \n                optimizer.zero_grad()\n                output = model(src, src_lens, trg)\n                \n                # Calculate loss\n                output_dim = output.shape[-1]\n                output = output[1:].view(-1, output_dim)\n                trg = trg[1:].view(-1)\n                \n                loss = criterion(output, trg)\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n                optimizer.step()\n                \n                total_loss += loss.item()\n            file_path = os.path.join(wandb.run.dir, \"model.pth\")\n            torch.save(model.state_dict(), file_path)\n            wandb.save('model.pth')\n            # Validation\n            #val_cer = evaluate_cer(model, dev_loader, device)\n            #val_wer = evaluate_wer(model, dev_loader, device)\n            val_acc = evaluate(model, dev_loader, device)\n            wandb.log({\n                'epoch': epoch,\n                'train_loss': total_loss/len(train_loader),\n                'val_acc': val_acc\n            })\n\ndef evaluate(model, loader, device):\n    model.eval()\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for src, trg, src_lens, trg_lens in loader:\n            src = src.to(device)\n            trg = trg.to(device)\n            \n            outputs = model(src, src_lens, trg, 0)  # No teacher forcing\n            outputs = outputs.argmax(dim=-1)\n            \n            # Calculate accuracy\n            mask = (trg != 0)\n            correct += ((outputs == trg) * mask).sum().item()\n            total += mask.sum().item()\n    \n    return correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T08:09:52.725446Z","iopub.execute_input":"2025-05-09T08:09:52.725741Z","iopub.status.idle":"2025-05-09T08:09:52.739651Z","shell.execute_reply.started":"2025-05-09T08:09:52.725721Z","shell.execute_reply":"2025-05-09T08:09:52.738511Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def train_with_beam(config=None):\n    with wandb.init(project=\"DA6401_A3\",settings=wandb.Settings(start_method=\"thread\",_disable_stats=True), config = config) as run:\n        config = run.config\n        \n        # Get dataloaders and vocabularies\n        train_loader, dev_loader, _, src_vocab, trg_vocab = get_dataloaders(\n            batch_size=config.batch_size\n        )\n        go_idx = trg_vocab.char2idx['<go>']\n        stop_idx = trg_vocab.char2idx['stop']\n        # Initialize model\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        \n        model = Seq2Seq(\n            input_dim=len(src_vocab.char2idx),\n            output_dim=len(trg_vocab.char2idx),\n            embed_dim=config.embedding_size,\n            hidden_dim=config.hidden_size,\n            num_layers=config.num_layers,\n            cell_type=config.cell_type,\n            dropout=config.dropout,\n            device=device,\n            go_idx = go_idx,\n            stop_idx = stop_idx,\n            vocab = trg_vocab\n        ).to(device)\n        \n        # Training setup\n        optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n        criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n        \n        # Training loop\n        for epoch in range(15):  # Fixed epoch count for sweep\n            model.train()\n            total_loss = 0\n            \n            for src, trg, src_lens, trg_lens in train_loader:\n                src = src.to(device)\n                trg = trg.to(device)\n                \n                optimizer.zero_grad()\n                output = model(src, src_lens, trg)\n                \n                # Calculate loss\n                output_dim = output.shape[-1]\n                output = output[1:].view(-1, output_dim)\n                trg = trg[1:].view(-1)\n                \n                loss = criterion(output, trg)\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n                optimizer.step()\n                \n                total_loss += loss.item()\n            file_path = os.path.join(wandb.run.dir, \"model.pth\")\n            torch.save(model.state_dict(), file_path)\n            wandb.save('model.pth')\n            # Validation\n            val_cer = evaluate_cer(model, dev_loader, device)\n            val_wer = evaluate_wer(model, dev_loader, device)\n            #val_acc = evaluate(model, dev_loader, device)\n            wandb.log({\n                'epoch': epoch,\n                'train_loss': total_loss/len(train_loader),\n                'val_char_err': val_cer,\n                'val_word_err': val_wer\n            })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T12:49:06.309751Z","iopub.execute_input":"2025-05-08T12:49:06.310028Z","iopub.status.idle":"2025-05-08T12:49:06.319097Z","shell.execute_reply.started":"2025-05-08T12:49:06.310009Z","shell.execute_reply":"2025-05-08T12:49:06.318443Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_loader, dev_loader, test_loader, src_vocab, trg_vocab = get_dataloaders()\nprint(f\"Source vocab size: {len(src_vocab.char2idx)}\")\nprint(f\"Target vocab size: {len(trg_vocab.char2idx)}\")\nprint(f\"Training batches: {len(train_loader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T08:09:58.370633Z","iopub.execute_input":"2025-05-09T08:09:58.371057Z","iopub.status.idle":"2025-05-09T08:10:51.401321Z","shell.execute_reply.started":"2025-05-09T08:09:58.371031Z","shell.execute_reply":"2025-05-09T08:10:51.400349Z"}},"outputs":[{"name":"stdout","text":"Downloading dataset...\nDataset extracted successfully\nSource vocab size: 30\nTarget vocab size: 67\nTraining batches: 691\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"TransliterationDataset('test').data[2][1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T07:51:10.310791Z","iopub.execute_input":"2025-05-09T07:51:10.311481Z","iopub.status.idle":"2025-05-09T07:51:10.360269Z","shell.execute_reply.started":"2025-05-09T07:51:10.311447Z","shell.execute_reply":"2025-05-09T07:51:10.359422Z"}},"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"'ं'"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"src_vocab.char2idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T07:12:18.407965Z","iopub.execute_input":"2025-05-09T07:12:18.408589Z","iopub.status.idle":"2025-05-09T07:12:18.414156Z","shell.execute_reply.started":"2025-05-09T07:12:18.408558Z","shell.execute_reply":"2025-05-09T07:12:18.413342Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"defaultdict(<function __main__.TransliterationVocabulary.__init__.<locals>.<lambda>()>,\n            {'<pad>': 0,\n             '<go>': 1,\n             '<stop>': 2,\n             '<unk>': 3,\n             'a': 4,\n             'n': 5,\n             'k': 6,\n             'g': 7,\n             'i': 8,\n             't': 9,\n             'u': 10,\n             'c': 11,\n             'l': 12,\n             'e': 13,\n             'r': 14,\n             's': 15,\n             'h': 16,\n             'd': 17,\n             'b': 18,\n             'y': 19,\n             'o': 20,\n             'j': 21,\n             'z': 22,\n             'm': 23,\n             'v': 24,\n             'w': 25,\n             'p': 26,\n             'f': 27,\n             'x': 28,\n             'q': 29})"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"src_vocab.idx2char","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T07:11:53.584824Z","iopub.execute_input":"2025-05-09T07:11:53.585404Z","iopub.status.idle":"2025-05-09T07:11:53.591355Z","shell.execute_reply.started":"2025-05-09T07:11:53.585377Z","shell.execute_reply":"2025-05-09T07:11:53.590473Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{0: '<pad>',\n 1: '<go>',\n 2: '<stop>',\n 3: '<unk>',\n 4: 'a',\n 5: 'n',\n 6: 'k',\n 7: 'g',\n 8: 'i',\n 9: 't',\n 10: 'u',\n 11: 'c',\n 12: 'l',\n 13: 'e',\n 14: 'r',\n 15: 's',\n 16: 'h',\n 17: 'd',\n 18: 'b',\n 19: 'y',\n 20: 'o',\n 21: 'j',\n 22: 'z',\n 23: 'm',\n 24: 'v',\n 25: 'w',\n 26: 'p',\n 27: 'f',\n 28: 'x',\n 29: 'q'}"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"'''# Initialize sweep\nsweep_id = wandb.sweep(\n    sweep=sweep_config,  # Your sweep configuration dictionary\n    project=\"DA6401_A3\",\n    entity=\"megh_m-iit-madras\"\n)\n\n# Run sweep agents\nwandb.agent(sweep_id, function=train, count = 10)'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T12:55:18.536586Z","iopub.execute_input":"2025-05-08T12:55:18.536851Z","iopub.status.idle":"2025-05-08T13:36:51.431080Z","shell.execute_reply.started":"2025-05-08T12:55:18.536832Z","shell.execute_reply":"2025-05-08T13:36:51.430527Z"},"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Create sweep with ID: ifzck3iv\nSweep URL: https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ya29hggg with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DA6401_A3' when running a sweep."},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250508_125524-ya29hggg</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/ya29hggg' target=\"_blank\">fragrant-sweep-1</a></strong> to <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/ya29hggg' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/ya29hggg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_loss</td><td>█▄▃▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>█▇▆▃▄▄▅▃▃▃▁▂▁▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.28027</td></tr><tr><td>val_acc</td><td>0.13921</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fragrant-sweep-1</strong> at: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/ya29hggg' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/ya29hggg</a><br> View project at: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250508_125524-ya29hggg/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v3nstyub with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DA6401_A3' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250508_130644-v3nstyub</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/v3nstyub' target=\"_blank\">crimson-sweep-2</a></strong> to <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/v3nstyub' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/v3nstyub</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▅▁▃▆█▇█▆▇▆▅▆▄▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.93551</td></tr><tr><td>val_acc</td><td>0.14853</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">crimson-sweep-2</strong> at: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/v3nstyub' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/v3nstyub</a><br> View project at: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250508_130644-v3nstyub/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ux42uzil with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DA6401_A3' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250508_130921-ux42uzil</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/ux42uzil' target=\"_blank\">crisp-sweep-3</a></strong> to <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/ux42uzil' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/ux42uzil</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_loss</td><td>█▄▃▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>█▇▃▆▂▄▅▃▃▁▄▃▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.52017</td></tr><tr><td>val_acc</td><td>0.13814</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">crisp-sweep-3</strong> at: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/ux42uzil' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/ux42uzil</a><br> View project at: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250508_130921-ux42uzil/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4ps4y0zs with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DA6401_A3' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250508_131405-4ps4y0zs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/4ps4y0zs' target=\"_blank\">serene-sweep-4</a></strong> to <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/4ps4y0zs' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/4ps4y0zs</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▆▅▅▃▁▅█▅▃▇▄▂▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.74028</td></tr><tr><td>val_acc</td><td>0.14253</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">serene-sweep-4</strong> at: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/4ps4y0zs' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/4ps4y0zs</a><br> View project at: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250508_131405-4ps4y0zs/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tjf10scf with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DA6401_A3' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250508_131643-tjf10scf</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/tjf10scf' target=\"_blank\">laced-sweep-5</a></strong> to <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/tjf10scf' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/tjf10scf</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_loss</td><td>█▄▃▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>█▇▅▄▆▄▂▂▂▁▃▃▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.31967</td></tr><tr><td>val_acc</td><td>0.13318</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">laced-sweep-5</strong> at: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/tjf10scf' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/tjf10scf</a><br> View project at: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250508_131643-tjf10scf/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qzgkeeka with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DA6401_A3' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250508_132006-qzgkeeka</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/qzgkeeka' target=\"_blank\">fanciful-sweep-6</a></strong> to <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/qzgkeeka' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/qzgkeeka</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_loss</td><td>█▆▅▅▄▄▃▃▃▂▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>█▁▃▄▂▆▅▆▇█▅▆▆▆▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>2.02461</td></tr><tr><td>val_acc</td><td>0.1183</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fanciful-sweep-6</strong> at: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/qzgkeeka' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/qzgkeeka</a><br> View project at: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250508_132006-qzgkeeka/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 26y2nwgk with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DA6401_A3' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250508_132249-26y2nwgk</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/26y2nwgk' target=\"_blank\">peach-sweep-7</a></strong> to <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/26y2nwgk' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/26y2nwgk</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▃▃▂█▆▄▃▂▂▂▃▁▁▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.49272</td></tr><tr><td>val_acc</td><td>0.13987</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">peach-sweep-7</strong> at: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/26y2nwgk' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/26y2nwgk</a><br> View project at: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250508_132249-26y2nwgk/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5mj291g6 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DA6401_A3' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250508_132521-5mj291g6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/5mj291g6' target=\"_blank\">super-sweep-8</a></strong> to <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/5mj291g6' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/5mj291g6</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_loss</td><td>█▇▆▅▄▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>▃▁▄▂▅▃▄▄▅▃█▆▆▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>1.39874</td></tr><tr><td>val_acc</td><td>0.13246</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">super-sweep-8</strong> at: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/5mj291g6' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/5mj291g6</a><br> View project at: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250508_132521-5mj291g6/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 12a1zp53 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DA6401_A3' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250508_132728-12a1zp53</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/12a1zp53' target=\"_blank\">devout-sweep-9</a></strong> to <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/12a1zp53' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/12a1zp53</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▄▇█▅▇▇█▆█▇▄█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.72946</td></tr><tr><td>val_acc</td><td>0.13313</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">devout-sweep-9</strong> at: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/12a1zp53' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/12a1zp53</a><br> View project at: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250508_132728-12a1zp53/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uf81l0g4 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DA6401_A3' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250508_133208-uf81l0g4</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/uf81l0g4' target=\"_blank\">earnest-sweep-10</a></strong> to <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/ifzck3iv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/uf81l0g4' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/uf81l0g4</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▄▃▃▂▂▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>▃▁▂▃▄▁█▇▅▆▆▇█▇▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>1.2443</td></tr><tr><td>val_acc</td><td>0.12701</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">earnest-sweep-10</strong> at: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/uf81l0g4' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/uf81l0g4</a><br> View project at: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250508_133208-uf81l0g4/logs</code>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"def show_alignment_example(model, sample):\n    src, trg = sample\n    pred = model.beam_search(src.unsqueeze(1), [len(src)], beam_width=1)[0][0]\n    \n    target_str = TransliterationMetrics.preprocess_sequence(trg[1:-1], model.decoder.vocab)\n    pred_str = TransliterationMetrics.preprocess_sequence(pred, model.decoder.vocab)\n    \n    print(\"CER:\", cer(target_str, pred_str))\n    print(\"Target:\", target_str)\n    print(\"Predicted:\", pred_str)\n    visualize_alignment(target_str, pred_str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:49:48.097237Z","iopub.execute_input":"2025-05-05T21:49:48.100299Z","iopub.status.idle":"2025-05-05T21:49:48.112000Z","shell.execute_reply.started":"2025-05-05T21:49:48.100258Z","shell.execute_reply":"2025-05-05T21:49:48.110552Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# For analysis\n'''sample = next(iter(dev_loader))\nshow_alignment_example(model, sample[0][0], sample[1][0])'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:49:55.807923Z","iopub.execute_input":"2025-05-05T21:49:55.808977Z","iopub.status.idle":"2025-05-05T21:49:55.882109Z","shell.execute_reply.started":"2025-05-05T21:49:55.808933Z","shell.execute_reply":"2025-05-05T21:49:55.878570Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/2271421838.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# For analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshow_alignment_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nbest_model = Seq2Seq(\n            input_dim=len(src_vocab.char2idx),\n            output_dim=len(trg_vocab.char2idx)+1,\n            embed_dim=128,\n            hidden_dim=256,\n            num_layers=1,\n            cell_type='LSTM',\n            dropout=0.2,\n            device=device,\n            go_idx = trg_vocab.char2idx['<go>'],\n            stop_idx = trg_vocab.char2idx['<stop>'],\n            vocab = trg_vocab\n        ).to(device)\nbest_model.load_state_dict(torch.load('/kaggle/input/model_no_beam/pytorch/default/1/model_no-beam.pth', map_location = torch.device('cpu'), weights_only = True))\nbest_model.eval()\nevaluate(best_model, test_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T08:11:20.561787Z","iopub.execute_input":"2025-05-09T08:11:20.562158Z","iopub.status.idle":"2025-05-09T08:11:23.345052Z","shell.execute_reply.started":"2025-05-09T08:11:20.562132Z","shell.execute_reply":"2025-05-09T08:11:23.343776Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"0.13594314079422382"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"with torch.no_grad():\n        for src, trg, src_lens, trg_lens in test_loader:\n            src = src.to(device)\n            trg = trg.to(device)\n            \n            outputs = best_model(src, src_lens, trg, 0)  # No teacher forcing\n            #outputs = outputs.argmax(dim=-1)\n\noutputs.size()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:22:08.401776Z","iopub.execute_input":"2025-05-08T07:22:08.402149Z","iopub.status.idle":"2025-05-08T07:22:10.203889Z","shell.execute_reply.started":"2025-05-08T07:22:08.402121Z","shell.execute_reply":"2025-05-08T07:22:10.202979Z"},"jupyter":{"source_hidden":true}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"torch.Size([3, 22, 15])"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"results = []\nwith torch.no_grad():\n    for src, trg, src_lens, trg_lens in test_loader:\n        src = src.to(device)\n        \n        # Forward pass through encoder\n        encoder_outputs, hidden = best_model.encoder(src, src_lens)\n        \n        # Greedy decoding\n        batch_size = src.size(1)\n        decoder_input = torch.full((1, batch_size), best_model.decoder.go_idx, device=device, dtype=torch.long)\n        \n        predictions = torch.zeros(50, batch_size, device=device, dtype=torch.long)\n\n        for t in range(50):\n            decoder_output, hidden = best_model.decoder(decoder_input.squeeze(0), hidden)\n            topi = decoder_output.argmax(1)\n            predictions[t] = topi\n            decoder_input = topi.unsqueeze(0)\n\n        # Process batch\n        for i in range(batch_size):\n            # Get source sequence\n            src_indices = src[:,i].cpu().numpy()\n            src_str = ''.join([src_vocab.idx2char[idx] for idx in src_indices if idx not in [0,1,2,3]])\n            \n            # Get prediction\n            pred_indices = predictions[:,i].cpu().numpy()\n            pred_str = ''.join([trg_vocab.idx2char[idx] for idx in pred_indices if idx not in [0,1,2,3]])\n            \n            results.append({\n                'Source': src_str,\n                'Prediction': pred_str,\n                'Target': ''.join([trg_vocab.idx2char[idx] for idx in trg[:,i].cpu().numpy() if idx not in [0,1,2,3]])\n            })\n\npd.DataFrame(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T08:25:42.086342Z","iopub.execute_input":"2025-05-09T08:25:42.087456Z","iopub.status.idle":"2025-05-09T08:25:49.077505Z","shell.execute_reply.started":"2025-05-09T08:25:42.087422Z","shell.execute_reply":"2025-05-09T08:25:49.076626Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"            Source Prediction     Target\n0              ank        अंक        अंक\n1             anka       अंका        अंक\n2            ankgi      अंगीक      अंकगण\n3           anaktn      अंकतन      अंकिं\n4           ankutn     अंकुटन      अंकिं\n...            ...        ...        ...\n4497       utzbgnc    उज्टबंग   ैिजरचगंल\n4498  utvuancayaab  उत्वााबां  ैिईंलुीुा\n4499   utvuancayab   उत्वांबा  ैिईंलुीुा\n4500        utvirv    उत्ववरी    ैिडरवूड\n4501       utvirvv   उत्ववववर    ैिडरवूड\n\n[4502 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Source</th>\n      <th>Prediction</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ank</td>\n      <td>अंक</td>\n      <td>अंक</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>anka</td>\n      <td>अंका</td>\n      <td>अंक</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ankgi</td>\n      <td>अंगीक</td>\n      <td>अंकगण</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>anaktn</td>\n      <td>अंकतन</td>\n      <td>अंकिं</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ankutn</td>\n      <td>अंकुटन</td>\n      <td>अंकिं</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4497</th>\n      <td>utzbgnc</td>\n      <td>उज्टबंग</td>\n      <td>ैिजरचगंल</td>\n    </tr>\n    <tr>\n      <th>4498</th>\n      <td>utvuancayaab</td>\n      <td>उत्वााबां</td>\n      <td>ैिईंलुीुा</td>\n    </tr>\n    <tr>\n      <th>4499</th>\n      <td>utvuancayab</td>\n      <td>उत्वांबा</td>\n      <td>ैिईंलुीुा</td>\n    </tr>\n    <tr>\n      <th>4500</th>\n      <td>utvirv</td>\n      <td>उत्ववरी</td>\n      <td>ैिडरवूड</td>\n    </tr>\n    <tr>\n      <th>4501</th>\n      <td>utvirvv</td>\n      <td>उत्ववववर</td>\n      <td>ैिडरवूड</td>\n    </tr>\n  </tbody>\n</table>\n<p>4502 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"src_vocab.char2idx['a']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T07:52:23.281497Z","iopub.execute_input":"2025-05-09T07:52:23.281771Z","iopub.status.idle":"2025-05-09T07:52:23.287240Z","shell.execute_reply.started":"2025-05-09T07:52:23.281754Z","shell.execute_reply":"2025-05-09T07:52:23.286503Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"4"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nwith torch.no_grad():\n    for src, trg, src_lens, trg_lens in test_loader:\n        src = src.to(device)\n        trg = trg.to(device)\n        for i in range(1):\n            # Get source sequence\n            src_indices = src[:,i].cpu().numpy()\n            src_str = ''.join([src_vocab.idx2char[idx] for idx in src_indices if idx not in [0, 1, 2, 3]])\n            print(src_str) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T08:02:45.757357Z","iopub.execute_input":"2025-05-09T08:02:45.758367Z","iopub.status.idle":"2025-05-09T08:02:45.911574Z","shell.execute_reply.started":"2025-05-09T08:02:45.758331Z","shell.execute_reply":"2025-05-09T08:02:45.910661Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"ank\naiiuav\nayyaavg\nazg\ngoj\ntlbrl\nrkaiiug\ndiuaoaiak\ndzauana\nrwalmr\ntvaka\nkayl\nxasg\nktti\njzrlgv\ncar\ncazaqgtn\njuanblahatn\njughaig\njuudoakal\neahdag\neaankaltn\nedbag\nepaltn\nitnca\nbdznr\nialaycane\nireaeg\nballa\nbgmwa\nbuaiana\nnakvazgwtn\nnad\nnglyaabu\noanjuaanc\noalaaburrn\noaiuwaklah\nogbgwa\noalailttorl\nolantn\nfazia\nftni\nyabaia\nyanyg\nygccrvi\nyanbacr\nyuayutti\nyuaglt\nhawtlkaa\nhancang\nhdyalkodl\nhabr\nwaina\nlaae\nlrria\nltwazv\nzazkalia\nzrikal\nmrlvgtn\nmgbwaawrgn\nmrltngka\nvulaytn\nvulglah\nvanviugia\nvalkalrgn\nvawan\nvugrzb\nvrnbua\nviltkrv\nuahazamal\nudooal\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"src_str","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T08:02:51.137709Z","iopub.execute_input":"2025-05-09T08:02:51.138392Z","iopub.status.idle":"2025-05-09T08:02:51.143202Z","shell.execute_reply.started":"2025-05-09T08:02:51.138369Z","shell.execute_reply":"2025-05-09T08:02:51.142359Z"}},"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"'udooal'"},"metadata":{}}],"execution_count":68},{"cell_type":"code","source":"src, trg = TransliterationDataset('test').data[2]\nfor c in src:\n    print(c)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T08:05:36.637329Z","iopub.execute_input":"2025-05-09T08:05:36.637914Z","iopub.status.idle":"2025-05-09T08:05:36.683569Z","shell.execute_reply.started":"2025-05-09T08:05:36.637888Z","shell.execute_reply":"2025-05-09T08:05:36.682902Z"}},"outputs":[{"name":"stdout","text":"a\nn\nk\ni\nt\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"[src_vocab.char2idx['<go>']] + [src_vocab.char2idx[c] for c in src if c not in ['<go>','<stop>','<pad>','<unk>']] +[src_vocab.char2idx['<stop>']]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T08:05:39.084530Z","iopub.execute_input":"2025-05-09T08:05:39.085429Z","iopub.status.idle":"2025-05-09T08:05:39.091517Z","shell.execute_reply.started":"2025-05-09T08:05:39.085405Z","shell.execute_reply":"2025-05-09T08:05:39.090709Z"}},"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"[1, 4, 5, 6, 8, 9, 2]"},"metadata":{}}],"execution_count":78},{"cell_type":"markdown","source":"# With Attention","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}