{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import wandb\nwandb.login(key = \"eb9574fa5b11da36782604ea27df8bf1989ddefd\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:05:25.985877Z","iopub.execute_input":"2025-05-05T15:05:25.986201Z","iopub.status.idle":"2025-05-05T15:05:34.965811Z","shell.execute_reply.started":"2025-05-05T15:05:25.986178Z","shell.execute_reply":"2025-05-05T15:05:34.965125Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmegh_m\u001b[0m (\u001b[33mmegh_m-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_SILENT\"] = \"false\"\nos.environ[\"WANDB_START_METHOD\"] = \"thread\"\nos.environ[\"WANDB_API_KEY\"] = \"eb9574fa5b11da36782604ea27df8bf1989ddefd\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:05:37.839109Z","iopub.execute_input":"2025-05-05T15:05:37.839571Z","iopub.status.idle":"2025-05-05T15:05:37.844293Z","shell.execute_reply.started":"2025-05-05T15:05:37.839547Z","shell.execute_reply":"2025-05-05T15:05:37.843359Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:19:40.971270Z","iopub.execute_input":"2025-05-05T15:19:40.971970Z","iopub.status.idle":"2025-05-05T15:19:40.976127Z","shell.execute_reply.started":"2025-05-05T15:19:40.971942Z","shell.execute_reply":"2025-05-05T15:19:40.975086Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"class CharEmbed(nn.Module):\n    def __init__(self, input_dim, embed_dim):\n        super(CharEmbed, self).__init__()\n        self.embed = nn.Embedding(input_dim, embed_dim)\n    \n    def forward(self, input_seq):\n        return self.embed(input_seq)\n\nclass EncoderRNN(nn.Module):\n    def __init__(self, input_dim, embed_dim, hidden_dim, n_layers=1, \n                 cell_type='GRU', dropout=0.0, bidirectional=False):\n        super(EncoderRNN, self).__init__()\n        self.embed = nn.Embedding(input_dim, embed_dim)\n        self.hidden_dim = hidden_dim\n        self.n_layers = n_layers\n        self.cell_type = cell_type\n        self.bidirectional = bidirectional #to allow forward and backward time step data processing\n        # Cell type options GRU, LSTM & vanilla RNN\n        if cell_type == 'GRU':\n            self.rnn = nn.GRU(embed_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0, bidirectional=bidirectional)\n        elif cell_type == 'LSTM':\n            self.rnn = nn.LSTM(embed_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0, bidirectional=bidirectional)\n        else: \n            self.rnn = nn.RNN(embed_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0, bidirectional=bidirectional)\n    \n    def forward(self, input_seq, input_lengths, hidden=None):\n        # Sort sequences by length\n        input_lengths, sort_idx = torch.sort(input_lengths, descending=True)\n        input_seq = input_seq[:, sort_idx]  # (seq_len, batch_size, ...)\n        \n        # Convert to embeddings\n        embedded = self.embed(input_seq)\n        \n        # Pack with enforce_sorted=False\n        packed = nn.utils.rnn.pack_padded_sequence(\n            embedded, \n            input_lengths.cpu(), \n            enforce_sorted=False\n        )\n        \n        # Forward pass\n        outputs, hidden = self.rnn(packed, hidden)\n        \n        # Unpack padding\n        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n        \n        # Restore original order\n        _, unsort_idx = torch.sort(sort_idx)\n        outputs = outputs[:, unsort_idx]\n        \n        # Handle LSTM hidden/cell states\n        if isinstance(hidden, tuple):\n            hidden = (\n                hidden[0][:, unsort_idx],  # Hidden state\n                hidden[1][:, unsort_idx]   # Cell state\n            )\n        else:  # For GRU/RNN\n            hidden = hidden[:, unsort_idx]\n        \n        return outputs, hidden\n\nclass DecoderRNN(nn.Module): #Basically similar to the encoder, will have a softmax to predict next char\n    def __init__(self, output_dim, embed_dim, hidden_dim, n_layers=1, cell_type='GRU', dropout=0.0):\n        super(DecoderRNN, self).__init__()\n        self.embed = nn.Embedding(output_dim, embed_dim)\n        self.hidden_dim = hidden_dim\n        self.output_dim = output_dim\n        self.n_layers = n_layers\n        self.cell_type = cell_type\n        if cell_type == 'GRU':\n            self.rnn = nn.GRU(embed_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0)\n        elif cell_type == 'LSTM':\n            self.rnn = nn.LSTM(embed_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0)\n        else:\n            self.rnn = nn.RNN(embed_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0)\n        \n        self.out = nn.Linear(hidden_dim, output_dim)\n        self.softmax = nn.LogSoftmax(dim=1)\n        \n    def forward(self, input, hidden):\n        # Get embedding of current input character\n        embedded = self.embed(input).unsqueeze(0)\n        \n        # Forward pass through decoder\n        output, hidden = self.rnn(embedded, hidden)\n        \n        # Predict next character probabilities\n        output = self.softmax(self.out(output.squeeze(0)))\n        \n        return output, hidden\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:18:51.163664Z","iopub.execute_input":"2025-05-05T15:18:51.163984Z","iopub.status.idle":"2025-05-05T15:18:51.178131Z","shell.execute_reply.started":"2025-05-05T15:18:51.163964Z","shell.execute_reply":"2025-05-05T15:18:51.177355Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"class Seq2Seq(nn.Module): #Flexible enough to use different encoders other than the ones we define\n    def __init__(self, input_dim, output_dim, embed_dim, \n                 hidden_dim, num_layers, cell_type, dropout, device):\n        #super().__init__()\n        super(Seq2Seq, self).__init__()\n        self.device = device\n            # Internal encoder creation\n        self.encoder = EncoderRNN(\n            input_dim=input_dim,\n            embed_dim=embed_dim,\n            hidden_dim=hidden_dim,\n            n_layers=num_layers,\n            cell_type=cell_type,\n            dropout=dropout\n        )\n        \n        # Internal decoder creation\n        self.decoder = DecoderRNN(\n            output_dim=output_dim,\n            embed_dim=embed_dim,\n            hidden_dim=hidden_dim,\n            n_layers=num_layers,\n            cell_type=cell_type,\n            dropout=dropout\n        )\n        \n        self.device = device \n    def forward(self, src, src_len, trg, teacher_forcing_ratio=0.5):\n        batch_size = src.shape[1]\n        trg_len = trg.shape[0]\n        trg_vocab_size = self.decoder.output_dim\n        \n        # Tensor to store decoder outputs\n        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n        \n        # Last hidden state of the encoder\n        encoder_outputs, hidden = self.encoder(src, src_len)\n        \n        # First input to the decoder is the <go> token\n        input = trg[0,:]\n        \n        for t in range(1, trg_len):\n            output, hidden = self.decoder(input, hidden)\n            outputs[t] = output\n            \n            # To Decide if we're going to use teacher forcing or not as needed\n            teacher_force = random.random() < teacher_forcing_ratio\n            \n            # Get the highest predicted token from our predictions\n            top1 = output.argmax(1)\n            \n            # If we use teacher forcing, we have to use actual next token as next input\n            # If not, use predicted token\n            input = trg[t] if teacher_force else top1\n        \n        return outputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:12:50.541093Z","iopub.execute_input":"2025-05-05T15:12:50.541774Z","iopub.status.idle":"2025-05-05T15:12:50.551500Z","shell.execute_reply.started":"2025-05-05T15:12:50.541744Z","shell.execute_reply":"2025-05-05T15:12:50.550582Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# Dataset Loading & Preprocessing","metadata":{}},{"cell_type":"code","source":"import os\nimport tarfile\nimport requests\nimport pandas as pd\nfrom io import BytesIO\nfrom collections import defaultdict\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nimport wandb\n\n# Dataset Configuration\nDATASET_URL = \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\"\nDATA_DIR = \"./dakshina_dataset\"\nHI_LEXICON_DIR = os.path.join(DATA_DIR,\"dakshina_dataset_v1.0\", \"hi\", \"lexicons\") #For Hindi (Chosen Language)\n\ndef download_and_extract_dataset(): #Scripted Dataset Download\n    if not os.path.exists(DATA_DIR):\n        print(\"Downloading dataset...\")\n        response = requests.get(DATASET_URL)\n        file = tarfile.open(fileobj=BytesIO(response.content))\n        file.extractall(DATA_DIR)\n        print(\"Dataset extracted successfully\")\n\nclass TransliterationVocabulary: #Build Character Vocab and add go,stop, padding and unknown tokens\n    def __init__(self):\n        self.char2idx = defaultdict(lambda: len(self.char2idx))\n        self.idx2char = {}\n        self.special_tokens = ['<pad>', '<go>', '<stop>', '<unk>']\n        \n        # Initialize special tokens\n        for token in self.special_tokens:\n            self.char2idx[token]\n        \n        self.idx2char = {v: k for k, v in self.char2idx.items()}\n    \n    def add_word(self, word):\n        #print(word) #for debugging\n        for char in word:\n            self.char2idx[char]\n        self.idx2char = {v: k for k, v in self.char2idx.items()}\n\nclass TransliterationDataset(Dataset): #Dataset loader for Hindi\n    def __init__(self, split='train'):\n        self.split = split\n        self.data = self._load_data()\n        self.src_vocab = TransliterationVocabulary()\n        self.trg_vocab = TransliterationVocabulary()\n        \n        # Build vocabularies\n        for pair in self.data:\n            self.src_vocab.add_word(pair[0])\n            self.trg_vocab.add_word(pair[1])\n    \n    def _load_data(self):\n        \"\"\"Load data from TSV files and filter non-string entries\"\"\"\n        file_map = {\n            'train': 'hi.translit.sampled.train.tsv',\n            'dev': 'hi.translit.sampled.dev.tsv',\n            'test': 'hi.translit.sampled.test.tsv'\n        }\n        \n        df = pd.read_csv(\n            os.path.join(HI_LEXICON_DIR, file_map[self.split]),\n            sep='\\t', \n            header=None,\n            names=['latin', 'devanagari'],\n            dtype={'latin': str, 'devanagari': str}  # Force string type\n        )\n        \n        # Filter out non-string entries and empty strings\n        valid_entries = [\n            (latin, devanagari) \n            for latin, devanagari in zip(df['latin'], df['devanagari'])\n            if (isinstance(latin, str) and \n                isinstance(devanagari, str) and\n                len(latin) > 0 and \n                len(devanagari) > 0)\n        ]\n        \n        return valid_entries\n\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        src, trg = self.data[idx]\n        return (\n            [self.src_vocab.char2idx['<go>']] + \n            [self.src_vocab.char2idx[c] for c in src] +\n            [self.src_vocab.char2idx['<stop>']],\n            [self.trg_vocab.char2idx['<go>']] + \n            [self.trg_vocab.char2idx[c] for c in trg] +\n            [self.trg_vocab.char2idx['<stop>']]\n        )\n\ndef collate_fn(batch): #Padding and Masking\n    src_batch, trg_batch = zip(*batch)\n    \n    src_lens = torch.tensor([len(x) for x in src_batch])\n    trg_lens = torch.tensor([len(x) for x in trg_batch])\n    \n    src_pad = pad_sequence(\n        [torch.tensor(x) for x in src_batch],\n        padding_value=0  # <pad> token index\n    )\n    \n    trg_pad = pad_sequence(\n        [torch.tensor(x) for x in trg_batch],\n        padding_value=0  # <pad> token index\n    )\n    \n    return src_pad, trg_pad, src_lens, trg_lens\n\ndef get_dataloaders(batch_size=64):\n    \"\"\"Create train, dev, test dataloaders\"\"\"\n    download_and_extract_dataset()\n    \n    train_dataset = TransliterationDataset('train')\n    dev_dataset = TransliterationDataset('dev')\n    test_dataset = TransliterationDataset('test')\n    \n    return (\n        DataLoader(train_dataset, batch_size=batch_size, \n                  shuffle=True, collate_fn=collate_fn),\n        DataLoader(dev_dataset, batch_size=batch_size, \n                 collate_fn=collate_fn),\n        DataLoader(test_dataset, batch_size=batch_size,\n                 collate_fn=collate_fn),\n        train_dataset.src_vocab,\n        train_dataset.trg_vocab\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:12:08.628618Z","iopub.execute_input":"2025-05-05T15:12:08.629322Z","iopub.status.idle":"2025-05-05T15:12:08.645038Z","shell.execute_reply.started":"2025-05-05T15:12:08.629299Z","shell.execute_reply":"2025-05-05T15:12:08.644117Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def beam_search_decode(model, src, src_len, beam_size, max_len, device):\n    # Encode source sequence\n    encoder_outputs, encoder_hidden = model.encoder(src, src_len)\n    \n    # Initialize beam\n    GO_token = model.decoder.vocab['<go>']\n    beam = [BeamNode([SOS_token], encoder_hidden, 0.0)]\n    \n    for step in range(max_len):\n        candidates = []\n        for node in beam:\n            if node.is_finished():\n                candidates.append(node)\n                continue\n            \n            # Prepare decoder input\n            input_tensor = torch.LongTensor([node.tokens[-1]]).to(device)\n            \n            # Decoder step\n            log_probs, hidden = model.decoder.beam_step(\n                input_tensor, \n                node.hidden,\n                encoder_outputs\n            )\n            \n            # Expand candidates\n            topk_probs, topk_ids = log_probs.topk(beam_size)\n            for i in range(beam_size):\n                token = topk_ids[0][i].item()\n                score = node.score + topk_probs[0][i].item()\n                new_node = BeamNode(\n                    node.tokens + [token],\n                    hidden,\n                    score,\n                    token == model.decoder.vocab['<stop>']\n                )\n                candidates.append(new_node)\n        \n        # Select top-k candidates\n        candidates.sort(reverse=True)\n        beam = candidates[:beam_size]\n        \n        # Early stopping if all beams finished\n        if all(node.is_finished() for node in beam):\n            break\n    \n    return beam[0].tokens[1:-1]  # Remove SOS and EOS\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"download_and_extract_dataset()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T16:50:18.993910Z","iopub.execute_input":"2025-05-03T16:50:18.994212Z","iopub.status.idle":"2025-05-03T16:50:32.463131Z","shell.execute_reply.started":"2025-05-03T16:50:18.994158Z","shell.execute_reply":"2025-05-03T16:50:32.462460Z"}},"outputs":[{"name":"stdout","text":"Downloading dataset...\nDataset extracted successfully\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"\ndf = pd.read_csv(\n            os.path.join(HI_LEXICON_DIR,'hi.translit.sampled.train.tsv'),\n            sep='\\t',  #specifying seperator\n            header=None,\n            names=['devanagari','latin','syllables']\n        )\nlist(zip(df['latin'], df['devanagari']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:53:28.399570Z","iopub.execute_input":"2025-05-03T17:53:28.399889Z","iopub.status.idle":"2025-05-03T17:53:28.471277Z","shell.execute_reply.started":"2025-05-03T17:53:28.399865Z","shell.execute_reply":"2025-05-03T17:53:28.470488Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"44204"},"metadata":{}}],"execution_count":42},{"cell_type":"markdown","source":"# Train Sweep","metadata":{}},{"cell_type":"code","source":"sweep_config = {\n    'method': 'bayes',\n    'metric': {'name': 'val_acc', 'goal': 'maximize'},\n    'parameters': {\n        'embedding_size': {'values': [64, 128, 256]},\n        'hidden_size': {'values': [128, 256, 512]},\n        'num_layers': {'values': [1, 2, 3]},\n        'cell_type': {'values': ['LSTM', 'GRU', 'RNN']},\n        'dropout': {'values': [0.2, 0.3]},\n        'learning_rate': {'values': [0.001, 0.0005, 0.0001]},\n        'batch_size': {'values': [32, 64, 128]}\n    }\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:06:42.916535Z","iopub.execute_input":"2025-05-05T15:06:42.916813Z","iopub.status.idle":"2025-05-05T15:06:42.922279Z","shell.execute_reply.started":"2025-05-05T15:06:42.916794Z","shell.execute_reply":"2025-05-05T15:06:42.921439Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def train(config=None):\n    with wandb.init(project=\"DA6401_A3\",settings=wandb.Settings(start_method=\"thread\",_disable_stats=True), config = config) as run:\n        config = run.config\n        \n        # Get dataloaders and vocabularies\n        train_loader, dev_loader, _, src_vocab, trg_vocab = get_dataloaders(\n            batch_size=config.batch_size\n        )\n        \n        # Initialize model\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        \n        model = Seq2Seq(\n            input_dim=len(src_vocab.char2idx),\n            output_dim=len(trg_vocab.char2idx),\n            embed_dim=config.embedding_size,\n            hidden_dim=config.hidden_size,\n            num_layers=config.num_layers,\n            cell_type=config.cell_type,\n            dropout=config.dropout,\n            device=device\n        ).to(device)\n        \n        # Training setup\n        optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n        criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n        \n        # Training loop\n        for epoch in range(10):  # Fixed epoch count for sweep\n            model.train()\n            total_loss = 0\n            \n            for src, trg, src_lens, trg_lens in train_loader:\n                src = src.to(device)\n                trg = trg.to(device)\n                \n                optimizer.zero_grad()\n                output = model(src, src_lens, trg)\n                \n                # Calculate loss\n                output_dim = output.shape[-1]\n                output = output[1:].view(-1, output_dim)\n                trg = trg[1:].view(-1)\n                \n                loss = criterion(output, trg)\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n                optimizer.step()\n                \n                total_loss += loss.item()\n            \n            # Validation\n            val_acc = evaluate(model, dev_loader, device)\n            wandb.log({\n                'epoch': epoch,\n                'train_loss': total_loss/len(train_loader),\n                'val_acc': val_acc\n            })\n\ndef evaluate(model, loader, device):\n    model.eval()\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for src, trg, src_lens, trg_lens in loader:\n            src = src.to(device)\n            trg = trg.to(device)\n            \n            outputs = model(src, src_lens, trg, 0)  # No teacher forcing\n            outputs = outputs.argmax(dim=-1)\n            \n            # Calculate accuracy\n            mask = (trg != 0)\n            correct += ((outputs == trg) * mask).sum().item()\n            total += mask.sum().item()\n    \n    return correct / total\n\n# To start the sweep:\n# wandb sweep config.yaml\n# Then run agents with:\n# wandb agent SWEEP_ID\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:12:37.570176Z","iopub.execute_input":"2025-05-05T15:12:37.570493Z","iopub.status.idle":"2025-05-05T15:12:37.580779Z","shell.execute_reply.started":"2025-05-05T15:12:37.570469Z","shell.execute_reply":"2025-05-05T15:12:37.579889Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"train_loader, dev_loader, test_loader, src_vocab, trg_vocab = get_dataloaders()\nprint(f\"Source vocab size: {len(src_vocab.char2idx)}\")\nprint(f\"Target vocab size: {len(trg_vocab.char2idx)}\")\nprint(f\"Training batches: {len(train_loader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:12:25.515536Z","iopub.execute_input":"2025-05-05T15:12:25.515854Z","iopub.status.idle":"2025-05-05T15:12:25.825939Z","shell.execute_reply.started":"2025-05-05T15:12:25.515834Z","shell.execute_reply":"2025-05-05T15:12:25.825167Z"}},"outputs":[{"name":"stdout","text":"Source vocab size: 30\nTarget vocab size: 14\nTraining batches: 691\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Initialize sweep\nsweep_id = wandb.sweep(\n    sweep=sweep_config,  # Your sweep configuration dictionary\n    project=\"DA6401_A3\",\n    entity=\"megh_m-iit-madras\"\n)\n\n# Run sweep agents\nwandb.agent(sweep_id, function=train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:19:48.454027Z","iopub.execute_input":"2025-05-05T15:19:48.454728Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: vew3zh1e\nSweep URL: https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/vew3zh1e\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k3oiog37 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DA6401_A3' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250505_151955-k3oiog37</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/k3oiog37' target=\"_blank\">youthful-sweep-1</a></strong> to <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/vew3zh1e' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/vew3zh1e</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/vew3zh1e' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/sweeps/vew3zh1e</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/k3oiog37' target=\"_blank\">https://wandb.ai/megh_m-iit-madras/DA6401_A3/runs/k3oiog37</a>"},"metadata":{}}],"execution_count":null}]}